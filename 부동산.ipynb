{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "import copy\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "# pypi packages\n",
    "import os\n",
    "# langchain\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# info\n",
    "# import pandas as pd\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "# duckduckgo\n",
    "from duckduckgo_search import DDGS\n",
    "import time\n",
    "# translation\n",
    "import copy\n",
    "# formatting\n",
    "import markdown2\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버지도 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# DataFrame에서 첫 번째 동 가져오기\n",
    "region = ''\n",
    "query = f\"{region} 아동상담\"\n",
    "\n",
    "# 요청 URL 및 페이로드 설정\n",
    "url = \"https://map.naver.com/p/api/search/allSearch\"\n",
    "payload = {\n",
    "    \"query\": query,\n",
    "    \"type\": \"all\",\n",
    "    \"searchCoord\": \"126.84964199999752;37.55093699999992\",\n",
    "    \"boundary\": \"\",\n",
    "}\n",
    "\n",
    "# 요청 헤더 설정\n",
    "headers = {\n",
    "    \"Cookie\": \"NNB=X4AQ72WKVDWWK; _ga_EFBDNNF91G=GS1.1.1710342642.1.0.1710342642.0.0.0; _ga=GA1.2.1432322870.1710342643; ASID=de6c8eec0000018e4a6f6df000000057; ba.uuid=5bc9ada0-1bf0-4056-990b-4664443def51; _ga_6Z6DP60WFK=GS1.2.1715222690.1.1.1715222788.22.0.0; NAC=eWSqDYgPae4PA; nid_inf=682912469; NID_JKL=Ic/2rOkr+RL4ydcvmJ1tf+b3+CKU/FGh2FPy8zUx2Nw=; NACT=1; page_uid=iFgH0wqo1e8ssk4DuGlssssstfw-148679; BUC=KJMMRp7jtJxMZxUm53cFpzMPDyINF73LnU9XuP4CRHM=\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# 요청 보내기\n",
    "response = requests.get(url, headers=headers, params=payload)\n",
    "\n",
    "# 응답 출력\n",
    "print(response.status_code)\n",
    "response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def naver_smart_place(query, start=1, display=70) :\n",
    "    url = \"https://pcmap-api.place.naver.com/graphql\"\n",
    "    headers = {\n",
    "        # \"Accept\": \"*/*\",\n",
    "        # \"Accept-Encoding\": \"gzip, deflate, br, zstd\",\n",
    "        # \"Accept-Language\": \"ko\",\n",
    "        # \"Content-Length\": \"15350\",\n",
    "        # \"Content-Type\": \"application/json\",\n",
    "        \"Cookie\": \"NNB=X4AQ72WKVDWWK; _ga_EFBDNNF91G=GS1.1.1710342642.1.0.1710342642.0.0.0; _ga=GA1.2.1432322870.1710342643; ASID=de6c8eec0000018e4a6f6df000000057; ba.uuid=5bc9ada0-1bf0-4056-990b-4664443def51; _ga_6Z6DP60WFK=GS1.2.1715222690.1.1.1715222788.22.0.0; NAC=eWSqDYgPae4PA; nid_inf=682912469; NID_JKL=Ic/2rOkr+RL4ydcvmJ1tf+b3+CKU/FGh2FPy8zUx2Nw=; NACT=1; page_uid=iFRCMdqptbNsskpuqzGssssssEw-471214; BUC=dYjFxxKLxlmEB7sTqCrjq0HQErJ4M__bmzzImx7jrdI=\",\n",
    "        # \"Origin\": \"https://pcmap.place.naver.com\",\n",
    "        \"Priority\": \"u=1, i\",\n",
    "        \"Referer\": \"https://pcmap.place.naver.com/place/list?query=%EC%A2%85%EB%A1%9C%EA%B5%AC%20%EC%95%84%EB%8F%99%EC%83%81%EB%8B%B4&x=126.9788350000029&y=37.57352100000024&clientX=126.809723&clientY=37.470581&bounds=126.92467583557573%3B37.50321600239536%3B127.03471077820234%3B37.642400420982284&display=70&ts=1718954198458&mapUrl=https%3A%2F%2Fmap.naver.com%2Fp%2Fsearch%2F%EC%A2%85%EB%A1%9C%EA%B5%AC%20%EC%95%84%EB%8F%99%EC%83%81%EB%8B%B4\",\n",
    "        # \"Sec-Ch-Ua\": \"\\\"Not/A)Brand\\\";v=\\\"8\\\", \\\"Chromium\\\";v=\\\"126\\\", \\\"Google Chrome\\\";v=\\\"126\\\"\",\n",
    "        # \"Sec-Ch-Ua-Mobile\": \"?0\",\n",
    "        # \"Sec-Ch-Ua-Platform\": \"\\\"Windows\\\"\",\n",
    "        # \"Sec-Fetch-Dest\": \"empty\",\n",
    "        # \"Sec-Fetch-Mode\": \"cors\",\n",
    "        # \"Sec-Fetch-Site\": \"same-site\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\",\n",
    "        \"X-Wtm-Graphql\": \"eyJhcmciOiLsooXroZzqtawg7JWE64-Z7IOB64u0IiwidHlwZSI6InBsYWNlIiwic291cmNlIjoicGxhY2UifQ\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"operationName\": \"getPlacesList\",\n",
    "        \"variables\": {\n",
    "            \"useReverseGeocode\": True,\n",
    "            \"input\": {\n",
    "                \"query\": query,\n",
    "                \"start\": start,\n",
    "                \"display\": display,\n",
    "                \"adult\": False,\n",
    "                \"spq\": False,\n",
    "                \"queryRank\": \"\",\n",
    "                \"x\": \"126.9788350000029\",\n",
    "                \"y\": \"37.57352100000024\",\n",
    "                \"deviceType\": \"pcmap\",\n",
    "                \"bounds\": \"126.92467583557573;37.50321600239536;127.03471077820234;37.642400420982284\"\n",
    "            },\n",
    "            \"isNmap\": False,\n",
    "            \"isBounds\": True,\n",
    "            \"reverseGeocodingInput\": {\n",
    "                \"x\": \"126.809723\",\n",
    "                \"y\": \"37.470581\"\n",
    "            }\n",
    "        },\n",
    "        \"query\": \"\"\"\n",
    "        query getPlacesList($input: PlacesInput, $isNmap: Boolean!) {\n",
    "            businesses: places(input: $input) {\n",
    "                total\n",
    "                items {\n",
    "                    id\n",
    "                    name\n",
    "                    normalizedName\n",
    "                    category\n",
    "                    detailCid {\n",
    "                        c0\n",
    "                        c1\n",
    "                        c2\n",
    "                        c3\n",
    "                        __typename\n",
    "                    }\n",
    "                    categoryCodeList\n",
    "                    dbType\n",
    "                    distance\n",
    "                    roadAddress\n",
    "                    address\n",
    "                    fullAddress\n",
    "                    commonAddress\n",
    "                    bookingUrl\n",
    "                    phone\n",
    "                    virtualPhone\n",
    "                    businessHours\n",
    "                    daysOff\n",
    "                    imageUrl\n",
    "                    imageCount\n",
    "                    x\n",
    "                    y\n",
    "                    poiInfo {\n",
    "                        polyline {\n",
    "                            shapeKey {\n",
    "                                id\n",
    "                                name\n",
    "                                version\n",
    "                                __typename\n",
    "                            }\n",
    "                            boundary {\n",
    "                                minX\n",
    "                                minY\n",
    "                                maxX\n",
    "                                maxY\n",
    "                                __typename\n",
    "                            }\n",
    "                            details {\n",
    "                                totalDistance\n",
    "                                arrivalAddress\n",
    "                                departureAddress\n",
    "                                __typename\n",
    "                            }\n",
    "                            __typename\n",
    "                        }\n",
    "                        polygon {\n",
    "                            shapeKey {\n",
    "                                id\n",
    "                                name\n",
    "                                version\n",
    "                                __typename\n",
    "                            }\n",
    "                            boundary {\n",
    "                                minX\n",
    "                                minY\n",
    "                                maxX\n",
    "                                maxY\n",
    "                                __typename\n",
    "                            }\n",
    "                            __typename\n",
    "                        }\n",
    "                        __typename\n",
    "                    }\n",
    "                    subwayId\n",
    "                    markerId @include(if: $isNmap)\n",
    "                    markerLabel @include(if: $isNmap) {\n",
    "                        text\n",
    "                        style\n",
    "                        stylePreset\n",
    "                        __typename\n",
    "                    }\n",
    "                    imageMarker @include(if: $isNmap) {\n",
    "                        marker\n",
    "                        markerSelected\n",
    "                        __typename\n",
    "                    }\n",
    "                    oilPrice @include(if: $isNmap) {\n",
    "                        gasoline\n",
    "                        diesel\n",
    "                        lpg\n",
    "                        __typename\n",
    "                    }\n",
    "                    isPublicGas\n",
    "                    isDelivery\n",
    "                    isTableOrder\n",
    "                    isPreOrder\n",
    "                    isTakeOut\n",
    "                    isCvsDelivery\n",
    "                    hasBooking\n",
    "                    naverBookingCategory\n",
    "                    bookingDisplayName\n",
    "                    bookingBusinessId\n",
    "                    bookingVisitId\n",
    "                    bookingPickupId\n",
    "                    baemin {\n",
    "                        businessHours {\n",
    "                            deliveryTime {\n",
    "                                start\n",
    "                                end\n",
    "                                __typename\n",
    "                            }\n",
    "                            __typename\n",
    "                        }\n",
    "                        __typename\n",
    "                    }\n",
    "                    yogiyo {\n",
    "                        businessHours {\n",
    "                            actualDeliveryTime {\n",
    "                                start\n",
    "                                end\n",
    "                                __typename\n",
    "                            }\n",
    "                            __typename\n",
    "                        }\n",
    "                        __typename\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('korea_districts.csv', encoding='cp949', index_col=0)\n",
    "special_cities = ['서울특별시','인천광역시','광주광역시','부산광역시','대구광역시','대전광역시','울산광역시']\n",
    "special_city_df = df[df['0'].isin(special_cities)]\n",
    "ordinary_city_df = df[~df['0'].isin(special_cities)]\n",
    "\n",
    "new_df = df[['0', '1']]\n",
    "new_df_unique = new_df.drop_duplicates()\n",
    "\n",
    "sample = new_df_unique[new_df_unique['0'] == '인천광역시']\n",
    "cols = ['id','name', 'category', 'roadAddress','fullAddress', 'virtualPhone', 'x', 'y', 'businessHours','daysOff', 'phone', 'imageUrl']\n",
    "\n",
    "data = new_df_unique\n",
    "\n",
    "for idx in range(len(data)):\n",
    "    time.sleep(3)\n",
    "    region = f\"{data.iat[idx,0]} {data.iat[idx,1]}\"\n",
    "    q = f\"{region} 아동상담\"\n",
    "    print(region)\n",
    "\n",
    "    response = naver_smart_place(q)\n",
    "    \n",
    "    totalCount = response.json()['data']['businesses']['total']\n",
    "    filename = f'{q}_{totalCount}.csv'\n",
    "    filepath = os.path.join('아동상담', filename)\n",
    "    display = 70\n",
    "    times = totalCount // display\n",
    "    remainder = totalCount % display\n",
    "    responses = []\n",
    "\n",
    "    for i in range(times):\n",
    "        response = naver_smart_place(q, start=i * display + 1, display=display)\n",
    "        responses.append(response)\n",
    "    \n",
    "    # 마지막 요청에서 display 값을 나머지로 설정\n",
    "    if remainder != 0:\n",
    "        response = naver_smart_place(q, start=times * display + 1, display=remainder)\n",
    "        responses.append(response)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for res in responses:\n",
    "        for item in res.json()['data']['businesses']['items']:\n",
    "            result = {col: item.get(col, '') for col in cols}\n",
    "            results.append(result)\n",
    "\n",
    "    final = pd.DataFrame(results)\n",
    "    final.to_csv(filepath, encoding='cp949', errors='ignore')\n",
    "\n",
    "print(\"작업이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = '아동상담_백업'\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        \n",
    "        # Read CSV file\n",
    "        df = pd.read_csv(file_path, encoding='cp949', index_col=0)\n",
    "        \n",
    "        # Fill NaN values with empty string for the entire DataFrame\n",
    "        df = df.fillna('')\n",
    "        \n",
    "        # Save the modified DataFrame back to CSV\n",
    "        df.to_csv(file_path, encoding='cp949')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아동상담제거\n",
    "import os\n",
    "\n",
    "# '아동상담' 폴더 경로\n",
    "folder_path = '아동상담ver2'\n",
    "\n",
    "# 폴더 내 모든 파일 목록 가져오기\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# 파일 이름에서 '아동상담' 문자열 제거\n",
    "for file_name in files:\n",
    "    if '아동상담' in file_name:\n",
    "        new_file_name = file_name.replace('아동상담 ', '')\n",
    "        old_file_path = os.path.join(folder_path, file_name)\n",
    "        new_file_path = os.path.join(folder_path, new_file_name)\n",
    "        os.rename(old_file_path, new_file_path)\n",
    "\n",
    "print(\"파일 이름에서 '아동상담'을 제거했습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딴지역꺼제거\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# '아동상담' 폴더 경로\n",
    "folder_path = '아동상담ver2'\n",
    "cols = ['id','name', 'category', 'roadAddress','fullAddress', 'virtualPhone', 'x', 'y', 'businessHours','daysOff', 'phone', 'imageUrl']\n",
    "# 폴더 내 모든 CSV 파일 목록 가져오기\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# 각 CSV 파일 처리\n",
    "for file_name in csv_files:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # 파일 제목에서 지역명과 총 개수 추출 (예: \"충청북도 충주시 _20\")\n",
    "    base_name, count_str = file_name.rsplit('_', 1)\n",
    "    search_term = base_name.strip()\n",
    "    original_count = int(count_str.replace('.csv', ''))\n",
    "\n",
    "    if original_count == 0 :\n",
    "        pd.DataFrame(columns=cols).to_csv(file_path, index=False) \n",
    "        continue\n",
    "    \n",
    "    # CSV 파일 읽기\n",
    "    df = pd.read_csv(file_path, encoding='cp949', index_col=0)\n",
    "    df = df.fillna('')\n",
    "    \n",
    "    \n",
    "    # roadAddress 또는 fullAddress 칼럼에서 NaN 값을 제거하고 검색어를 포함하지 않는 데이터 제거\n",
    "    df = df.dropna(subset=['roadAddress', 'fullAddress'])\n",
    "    df_filtered = df[df['roadAddress'].str.contains(search_term) | df['fullAddress'].str.contains(search_term)]\n",
    "    \n",
    "    # 필터링된 데이터 수 계산\n",
    "    new_count = df_filtered.shape[0]\n",
    "    \n",
    "    # 필터링된 데이터를 다시 CSV 파일로 저장\n",
    "    new_file_name = f\"{search_term}_{new_count}.csv\"\n",
    "    new_file_path = os.path.join(folder_path, new_file_name)\n",
    "    df_filtered.to_csv(new_file_path, encoding='cp949', index=False)\n",
    "    \n",
    "    # 기존 파일 삭제\n",
    "    os.remove(file_path)\n",
    "    \n",
    "print(\"파일 처리 및 저장이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 갯수확인\n",
    "folder_path = '아동상담ver2'\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "count = 0\n",
    "for file in files :\n",
    "    count+=int(file.split('_')[1].replace('.csv', ''))\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지역별통합본 만들기\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# '아동상담' 폴더 경로\n",
    "folder_path = '아동상담ver2'\n",
    "output_folder_path = os.path.join(folder_path, '통합')\n",
    "\n",
    "# 통합할 큰 행정구역 목록\n",
    "file_names_to_merge = [\n",
    "    '서울특별시', '부산광역시', '대구광역시', '인천광역시', '광주광역시',\n",
    "    '대전광역시', '울산광역시', '세종특별자치시', '경기도', '강원특별자치도',\n",
    "    '충청북도', '충청남도', '전북특별자치도', '전라남도', '경상북도',\n",
    "    '경상남도', '제주특별자치도'\n",
    "]\n",
    "\n",
    "# '통합' 폴더 생성\n",
    "os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "# 폴더 내 모든 CSV 파일 목록 가져오기\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv') and '_통합' not in f]\n",
    "\n",
    "# 각 큰 행정구역별 작은 행정구역 데이터프레임 저장\n",
    "for region in file_names_to_merge:\n",
    "    region_files = [f for f in csv_files if f.startswith(region)]\n",
    "    if region_files:\n",
    "        output_file_path = os.path.join(output_folder_path, f'{region}_통합.xlsx')\n",
    "        combined_df = pd.DataFrame()\n",
    "        \n",
    "        # 첫 시트에 통합본 저장을 위해 데이터프레임을 미리 생성\n",
    "        with pd.ExcelWriter(output_file_path, engine='openpyxl') as writer:\n",
    "            # 먼저 통합본 시트 저장\n",
    "            for file_name in region_files:\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                \n",
    "                try:\n",
    "                    # 작은 행정구역 이름 추출 (예: \"제주시\" from \"제주특별자치도 제주시_47\")\n",
    "                    sub_region_name = file_name.split(' ')[1].split('_')[0]\n",
    "                except IndexError:\n",
    "                    print(f\"파일 이름 형식이 맞지 않음: {file_name}\")\n",
    "                    continue\n",
    "                \n",
    "                # CSV 파일 읽기\n",
    "                df = pd.read_csv(file_path, encoding='cp949')\n",
    "                \n",
    "                # 인덱스 초기화\n",
    "                df.reset_index(drop=True, inplace=True)\n",
    "                \n",
    "                # 통합 데이터프레임에 추가\n",
    "                combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "            \n",
    "            # 통합본 시트를 첫 시트로 저장\n",
    "            combined_df.to_excel(writer, sheet_name='통합본', index=False)\n",
    "\n",
    "            # 그 후에 각 작은 행정구역을 별도의 시트로 저장\n",
    "            for file_name in region_files:\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                \n",
    "                try:\n",
    "                    # 작은 행정구역 이름 추출 (예: \"제주시\" from \"제주특별자치도 제주시_47\")\n",
    "                    sub_region_name = file_name.split(' ')[1].split('_')[0]\n",
    "                except IndexError:\n",
    "                    print(f\"파일 이름 형식이 맞지 않음: {file_name}\")\n",
    "                    continue\n",
    "                \n",
    "                # CSV 파일 읽기\n",
    "                df = pd.read_csv(file_path, encoding='cp949')\n",
    "                \n",
    "                # 인덱스 초기화\n",
    "                df.reset_index(drop=True, inplace=True)\n",
    "                \n",
    "                # 각 작은 행정구역을 별도의 시트로 저장\n",
    "                df.to_excel(writer, sheet_name=sub_region_name, index=False)\n",
    "\n",
    "print(\"파일 통합 및 저장이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 폴더 경로 설정\n",
    "folder_path = os.path.join('아동상담ver2','통합')\n",
    "\n",
    "# 폴더 내 모든 엑셀 파일 불러오기\n",
    "excel_files = [file for file in os.listdir(folder_path) if file.endswith('.xlsx')]\n",
    "\n",
    "# 첫 번째 시트 데이터 프레임 리스트 초기화\n",
    "df_dict = {}\n",
    "\n",
    "# 각 엑셀 파일의 첫 번째 시트를 데이터 프레임으로 읽어와서 딕셔너리에 저장\n",
    "for file in excel_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_excel(file_path, sheet_name=0)\n",
    "    sheet_name = os.path.splitext(file)[0]  # 파일 이름을 시트 이름으로 사용\n",
    "    df_dict[sheet_name] = df\n",
    "\n",
    "# 데이터 프레임 합치기\n",
    "combined_df = pd.concat(df_dict.values(), ignore_index=True)\n",
    "\n",
    "# 통합 엑셀 파일로 저장\n",
    "with pd.ExcelWriter(os.path.join(folder_path,'combined_output.xlsx')) as writer:\n",
    "    for sheet_name, df in df_dict.items():\n",
    "        df.to_excel(writer, index=False, sheet_name=sheet_name)\n",
    "    combined_df.to_excel(writer, index=False, sheet_name='통합')\n",
    "len(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(os.path.join('아동상담2', '통합', 'combined_output.xlsx'))\n",
    "df = df.drop_duplicates(subset=['id'])\n",
    "print(len(df))\n",
    "\n",
    "list1 = list(combined_df['id'])\n",
    "list2 = list(df['id'])\n",
    "only_in_list1 = list(set(list1) - set(list2))\n",
    "only_in_list2 = list(set(list2) - set(list1))\n",
    "\n",
    "only_in_list2\n",
    "\n",
    "df[df['id'].isin(only_in_list2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_combined_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# '아동상담' 폴더 경로\n",
    "folder_path = '아동상담'\n",
    "output_folder_path = os.path.join(folder_path, '통합')\n",
    "\n",
    "# 전국 파일 경로\n",
    "nationwide_file_path = os.path.join(output_folder_path, '전국_통합.xlsx')\n",
    "\n",
    "# 통합할 큰 행정구역 목록\n",
    "file_names_to_merge = [\n",
    "    '서울특별시', '부산광역시', '대구광역시', '인천광역시', '광주광역시',\n",
    "    '대전광역시', '울산광역시', '세종특별자치시', '경기도', '강원특별자치도',\n",
    "    '충청북도', '충청남도', '전북특별자치도', '전라남도', '경상북도',\n",
    "    '경상남도', '제주특별자치도'\n",
    "]\n",
    "\n",
    "# '통합' 폴더 생성\n",
    "os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "# 전국 통합 데이터프레임 초기화\n",
    "nationwide_combined_df = pd.DataFrame()\n",
    "\n",
    "# 전국 파일 생성\n",
    "with pd.ExcelWriter(nationwide_file_path, engine='openpyxl') as nationwide_writer:\n",
    "    # 각 통합본 파일 처리\n",
    "    for region in file_names_to_merge:\n",
    "        region_file_path = os.path.join(output_folder_path, f'{region}_통합.xlsx')\n",
    "        if os.path.exists(region_file_path):\n",
    "            try:\n",
    "                # 각 지역 통합본 파일 읽기\n",
    "                region_df = pd.read_excel(region_file_path, sheet_name='통합본')\n",
    "                \n",
    "                # 전국 통합 데이터프레임에 추가\n",
    "                nationwide_combined_df = pd.concat([nationwide_combined_df, region_df], ignore_index=True)\n",
    "                \n",
    "                # 각 지역 통합본 시트를 전국 파일에 추가\n",
    "                region_df.to_excel(nationwide_writer, sheet_name=region, index=False)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {region_file_path}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # 완전 통합본 시트를 첫 시트로 저장\n",
    "    nationwide_combined_df.to_excel(nationwide_writer, sheet_name='완전통합', index=False)\n",
    "\n",
    "print(\"전국 파일 생성 및 저장이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "display = 70\n",
    "q = '국밥'\n",
    "response = naver_smart_place(q, start= i * display + 1, display=display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['id','name', 'category', 'roadAddress','fullAddress', 'virtualPhone', 'x', 'y', 'businessHours','daysOff', 'phone', 'imageUrl']\n",
    "a = response.json()['data']['businesses']['items'][0]\n",
    "\n",
    "b = {}\n",
    "for col in cols :\n",
    "    b[col] = a[col]\n",
    "b\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = naver_smart_place('조치원 아동상담')\n",
    "total = 0\n",
    "total += response.json()['data']['businesses']['total']\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버부동산원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_districts(cortarNo = \"0000000000\") :\n",
    "    import requests\n",
    "\n",
    "    cookies = {\n",
    "        'NNB': 'X4AQ72WKVDWWK',\n",
    "        '_ga_EFBDNNF91G': 'GS1.1.1710342642.1.0.1710342642.0.0.0',\n",
    "        '_ga': 'GA1.2.1432322870.1710342643',\n",
    "        'ASID': 'de6c8eec0000018e4a6f6df000000057',\n",
    "        'ba.uuid': '5bc9ada0-1bf0-4056-990b-4664443def51',\n",
    "        '_ga_6Z6DP60WFK': 'GS1.2.1715222690.1.1.1715222788.22.0.0',\n",
    "        '_fwb': '466u0Eh7yaUAZ21KUVztYh.1715756440721',\n",
    "        '_fwb': '177FzAmJvq2ZIC2aaw2bGEA.1716702331931',\n",
    "        'landHomeFlashUseYn': 'Y',\n",
    "        'NAC': 'eWSqDYgPae4PA',\n",
    "        'nhn.realestate.article.rlet_type_cd': 'A01',\n",
    "        'nhn.realestate.article.trade_type_cd': '\"\"',\n",
    "        'NACT': '1',\n",
    "        'page_uid': 'ioW/RdqVOsCssAdy5MKssssssko-448268',\n",
    "        '_naver_usersession_': 'Mm0sn45xW/KWUfblGsoyNQ==',\n",
    "        'REALESTATE': 'Mon%20Jul%2008%202024%2014%3A56%3A19%20GMT%2B0900%20(KST)',\n",
    "        'wcs_bt': '4f99b5681ce60:1720418179',\n",
    "        'BUC': 'ALuosgpXpFwx53eyy1kI1_LZEbyQrVqjHcIRoktl0zI=',\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        'accept': '*/*',\n",
    "        'accept-language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "        'authorization': 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IlJFQUxFU1RBVEUiLCJpYXQiOjE3MjA0MTgxNzksImV4cCI6MTcyMDQyODk3OX0.8tTZNWoblgDsDC_4rL8VCwmQOKqF7LBUr1gKDFp7tPo',\n",
    "        # 'cookie': 'NNB=X4AQ72WKVDWWK; _ga_EFBDNNF91G=GS1.1.1710342642.1.0.1710342642.0.0.0; _ga=GA1.2.1432322870.1710342643; ASID=de6c8eec0000018e4a6f6df000000057; ba.uuid=5bc9ada0-1bf0-4056-990b-4664443def51; _ga_6Z6DP60WFK=GS1.2.1715222690.1.1.1715222788.22.0.0; _fwb=466u0Eh7yaUAZ21KUVztYh.1715756440721; _fwb=177FzAmJvq2ZIC2aaw2bGEA.1716702331931; landHomeFlashUseYn=Y; NAC=eWSqDYgPae4PA; nhn.realestate.article.rlet_type_cd=A01; nhn.realestate.article.trade_type_cd=\"\"; NACT=1; page_uid=ioW/RdqVOsCssAdy5MKssssssko-448268; _naver_usersession_=Mm0sn45xW/KWUfblGsoyNQ==; REALESTATE=Mon%20Jul%2008%202024%2014%3A56%3A19%20GMT%2B0900%20(KST); wcs_bt=4f99b5681ce60:1720418179; BUC=ALuosgpXpFwx53eyy1kI1_LZEbyQrVqjHcIRoktl0zI=',\n",
    "        'priority': 'u=1, i',\n",
    "        'referer': 'https://new.land.naver.com/search?ms=37.5444094,127.0092879,16&a=APT:ABYG:JGC:OPST:OBYG:PRE:JGB&b=A1:B1:B2&e=RETAIL&f=3000&h=165&i=231&j=30&l=700&ad=true',\n",
    "        'sec-ch-ua': '\"Not/A)Brand\";v=\"8\", \"Chromium\";v=\"126\", \"Google Chrome\";v=\"126\"',\n",
    "        'sec-ch-ua-mobile': '?0',\n",
    "        'sec-ch-ua-platform': '\"Windows\"',\n",
    "        'sec-fetch-dest': 'empty',\n",
    "        'sec-fetch-mode': 'cors',\n",
    "        'sec-fetch-site': 'same-origin',\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36',\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        'cortarNo': cortarNo,\n",
    "    }\n",
    "\n",
    "    response = requests.get('https://new.land.naver.com/api/regions/list', params=params, cookies=cookies, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "result  =  get_districts()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_small_districts(cortarNo = \"1100000000\") :\n",
    "    import requests\n",
    "\n",
    "    cookies = {\n",
    "        'NNB': 'X4AQ72WKVDWWK',\n",
    "        '_ga_EFBDNNF91G': 'GS1.1.1710342642.1.0.1710342642.0.0.0',\n",
    "        '_ga': 'GA1.2.1432322870.1710342643',\n",
    "        'ASID': 'de6c8eec0000018e4a6f6df000000057',\n",
    "        'ba.uuid': '5bc9ada0-1bf0-4056-990b-4664443def51',\n",
    "        '_ga_6Z6DP60WFK': 'GS1.2.1715222690.1.1.1715222788.22.0.0',\n",
    "        '_fwb': '466u0Eh7yaUAZ21KUVztYh.1715756440721',\n",
    "        '_fwb': '177FzAmJvq2ZIC2aaw2bGEA.1716702331931',\n",
    "        'landHomeFlashUseYn': 'Y',\n",
    "        'NAC': 'eWSqDYgPae4PA',\n",
    "        'nhn.realestate.article.rlet_type_cd': 'A01',\n",
    "        'nhn.realestate.article.trade_type_cd': '\"\"',\n",
    "        'NACT': '1',\n",
    "        'page_uid': 'ioW/RdqVOsCssAdy5MKssssssko-448268',\n",
    "        '_naver_usersession_': 'Mm0sn45xW/KWUfblGsoyNQ==',\n",
    "        'REALESTATE': 'Mon%20Jul%2008%202024%2014%3A56%3A19%20GMT%2B0900%20(KST)',\n",
    "        'wcs_bt': '4f99b5681ce60:1720418179',\n",
    "        'BUC': 'ALuosgpXpFwx53eyy1kI1_LZEbyQrVqjHcIRoktl0zI=',\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        'accept': '*/*',\n",
    "        'accept-language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "        'authorization': 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IlJFQUxFU1RBVEUiLCJpYXQiOjE3MjA0MTgxNzksImV4cCI6MTcyMDQyODk3OX0.8tTZNWoblgDsDC_4rL8VCwmQOKqF7LBUr1gKDFp7tPo',\n",
    "        # 'cookie': 'NNB=X4AQ72WKVDWWK; _ga_EFBDNNF91G=GS1.1.1710342642.1.0.1710342642.0.0.0; _ga=GA1.2.1432322870.1710342643; ASID=de6c8eec0000018e4a6f6df000000057; ba.uuid=5bc9ada0-1bf0-4056-990b-4664443def51; _ga_6Z6DP60WFK=GS1.2.1715222690.1.1.1715222788.22.0.0; _fwb=466u0Eh7yaUAZ21KUVztYh.1715756440721; _fwb=177FzAmJvq2ZIC2aaw2bGEA.1716702331931; landHomeFlashUseYn=Y; NAC=eWSqDYgPae4PA; nhn.realestate.article.rlet_type_cd=A01; nhn.realestate.article.trade_type_cd=\"\"; NACT=1; page_uid=ioW/RdqVOsCssAdy5MKssssssko-448268; _naver_usersession_=Mm0sn45xW/KWUfblGsoyNQ==; REALESTATE=Mon%20Jul%2008%202024%2014%3A56%3A19%20GMT%2B0900%20(KST); wcs_bt=4f99b5681ce60:1720418179; BUC=ALuosgpXpFwx53eyy1kI1_LZEbyQrVqjHcIRoktl0zI=',\n",
    "        'priority': 'u=1, i',\n",
    "        'referer': 'https://new.land.naver.com/search?ms=37.5444094,127.0092879,16&a=APT:ABYG:JGC:OPST:OBYG:PRE:JGB&b=A1:B1:B2&e=RETAIL&f=3000&h=165&i=231&j=30&l=700&ad=true',\n",
    "        'sec-ch-ua': '\"Not/A)Brand\";v=\"8\", \"Chromium\";v=\"126\", \"Google Chrome\";v=\"126\"',\n",
    "        'sec-ch-ua-mobile': '?0',\n",
    "        'sec-ch-ua-platform': '\"Windows\"',\n",
    "        'sec-fetch-dest': 'empty',\n",
    "        'sec-fetch-mode': 'cors',\n",
    "        'sec-fetch-site': 'same-origin',\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36',\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        'cortarNo': cortarNo,\n",
    "    }\n",
    "\n",
    "    response = requests.get('https://new.land.naver.com/api/regions/list', params=params, cookies=cookies, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "result = get_small_districts()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동 이름 가져오기\n",
    "\n",
    "import requests\n",
    "\n",
    "def get_dong(cortarNo =\"1120000000\") :\n",
    "    url = \"https://new.land.naver.com/api/regions/list\"\n",
    "    headers = {\n",
    "        \"Cookie\": \"NNB=FCKCGABYXJBGM; ASID=de6c8eec0000018fe0e3f4d60000005d; NAC=r45BBMwegqUeB; NACT=1; nhn.realestate.article.rlet_type_cd=A01; nhn.realestate.article.trade_type_cd=; nhn.realestate.article.ipaddress_city=1100000000; _fwb=61LHhDmgSVSDTIn6beSYcT.1719020991264; landHomeFlashUseYn=Y; page_uid=iFhWwdqVOsCssiyk1dGsssssskR-268088; _fwb=61LHhDmgSVSDTIn6beSYcT.1719020991264; REALESTATE=Sat%20Jun%2022%202024%2011%3A04%3A44%20GMT%2B0900%20(KST); wcs_bt=4f99b5681ce60:1719021885; BUC=fZZA8_pWVcDwPBsokKy-ABqKINLnOafN4vdJCZoIdxs=\",\n",
    "        \"Referer\": \"https://new.land.naver.com/complexes?ms=37.554416,127.0195285,17&a=APT:ABYG:JGC:PRE&e=RETAIL\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        \"cortarNo\": cortarNo\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    data = response.json()\n",
    "    cortar_list = [( region['cortarNo'], region['cortarName'],) for region in data['regionList']]\n",
    "    return data\n",
    "\n",
    "result = get_dong()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아파트 목록가져오기\n",
    "import requests\n",
    "\n",
    "def get_apts(cortarNo = \"1120011000\") :\n",
    "\n",
    "    url = \"https://new.land.naver.com/api/regions/complexes\"\n",
    "    headers = {\n",
    "        \"Cookie\": \"NNB=FCKCGABYXJBGM; ASID=de6c8eec0000018fe0e3f4d60000005d; NAC=r45BBMwegqUeB; NACT=1; nhn.realestate.article.rlet_type_cd=A01; nhn.realestate.article.trade_type_cd=; nhn.realestate.article.ipaddress_city=1100000000; _fwb=61LHhDmgSVSDTIn6beSYcT.1719020991264; landHomeFlashUseYn=Y; page_uid=iFhWwdqVOsCssiyk1dGsssssskR-268088; _fwb=61LHhDmgSVSDTIn6beSYcT.1719020991264; REALESTATE=Sat%20Jun%2022%202024%2011%3A04%3A44%20GMT%2B0900%20(KST); wcs_bt=4f99b5681ce60:1719021885; BUC=fZZA8_pWVcDwPBsokKy-ABqKINLnOafN4vdJCZoIdxs=\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        \"cortarNo\": cortarNo,\n",
    "        \"realEstateType\": \"APT:PRE\",\n",
    "        \"order\": \"\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    data = response.json()\n",
    "    cortar_list = [( region['complexNo'], region['complexName'],) for region in data['complexList']]\n",
    "    return data\n",
    "\n",
    "result = get_apts()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for district in total_districts :\n",
    "    no_district, name_district = district[0], district[1]\n",
    "    \n",
    "    dongs = get_dong(no_district)\n",
    "\n",
    "    for dong in dongs : \n",
    "        no_dong, name_dong = dong[0], dong[1]\n",
    "\n",
    "        apts = get_apts(no_dong)\n",
    "\n",
    "        for apt in apts :\n",
    "            no_apt, name_apt = apt[0], apt[1]\n",
    "            results.append((no_district,name_district,no_dong,name_dong,no_apt,name_apt))\n",
    "results\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "df.columns = ['cortarNo_district','cortarName_district','cortarName_dong','name_dong','complexNo','complexName']\n",
    "df\n",
    "\n",
    "path = os.path.join('부동산', '전국.csv')\n",
    "df.to_csv(path, encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import copy\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "class Naver_seoul_land() :\n",
    "    def __doc__(self) : \n",
    "        print(\"\"\"\n",
    "네이버부동산 크롤링 클래스입니다.\n",
    "사용방법은 다음과 같습니다.\n",
    "\n",
    "1. \n",
    "              \"\"\")\n",
    "        \n",
    "    def __init__(self) :\n",
    "        self.base_dir = '부동산'\n",
    "        if not os.path.exists(self.base_dir):\n",
    "            os.mkdir(self.base_dir)\n",
    "\n",
    "        self.total_apts_dir = os.path.join(self.base_dir, '전국.csv')        \n",
    "        self.total_apts = pd.read_csv(self.total_apts_dir, encoding='cp949')\n",
    "        self.apts = self.total_apts.copy()\n",
    "\n",
    "        self.cols_article = ['articleNo', 'articleName', 'realEstateTypeName', 'tradeTypeName', 'floorInfo', 'isPriceModification', 'dealOrWarrantPrc', 'areaName', 'area1', 'area2', 'direction', 'articleConfirmYmd', 'articleFeatureDesc', 'tagList', 'buildingName', 'sameAddrCnt', 'sameAddrMaxPrc', 'sameAddrMinPrc', 'pyeongs']\n",
    "        self.cols_trade = ['tradeType', 'floor' ,'formattedPrice', 'formattedTradeYearMonth']\n",
    "        self.cols_info = ['complexTypeName', 'complexName', 'totalHouseHoldCount', 'totalDongCount', 'useApproveYmd', 'minArea', 'maxArea']\n",
    "        self.cols_pyeongs = ['pyeongs']\n",
    "\n",
    "    def config_district(self, name_district) :\n",
    "        \"\"\"지역설정\"\"\"\n",
    "        self.district_dir = os.path.join(self.base_dir, name_district)\n",
    "        if not os.path.exists(self.district_dir):\n",
    "            os.mkdir(self.district_dir)\n",
    "        self.apts_dir = os.path.join(self.district_dir, f'{name_district}.csv')\n",
    "        self.article_dir = os.path.join(self.district_dir, f'{name_district}_매물.csv')\n",
    "        self.trade_dir = os.path.join(self.district_dir, f'{name_district}_실거래.csv')\n",
    "        self.info_dir = os.path.join(self.district_dir, f'{name_district}_정보.csv')\n",
    "\n",
    "        self.apts = self.total_apts[self.total_apts['cortarName_district'] == name_district]\n",
    "        self.apts.reset_index(drop=True, inplace=True)\n",
    "        self.apts.to_csv(os.path.join('부동산', name_district, f'{name_district}.csv'), encoding='cp949', index=False)\n",
    "\n",
    "        self.renew()\n",
    "\n",
    "    def renew(self) :\n",
    "        try :\n",
    "            self.apts_info = self.load('info')\n",
    "        except :\n",
    "            pass\n",
    "        try :\n",
    "            self.apts_article = self.load('article')\n",
    "        except :\n",
    "            pass\n",
    "        try :\n",
    "            self.apts_trade = self.load('trade')\n",
    "        except :\n",
    "            pass\n",
    "\n",
    "\n",
    "    def save(self, data, kind) :\n",
    "        if isinstance(data, dict) and all(isinstance(v, (int, float, str)) for v in data.values()):\n",
    "            df = pd.DataFrame([data])\n",
    "\n",
    "        else:\n",
    "            df = pd.DataFrame(data)\n",
    "\n",
    "        def convert_price(x):\n",
    "            if isinstance(x, int):\n",
    "                return x * 10000 if x <= 100 else x\n",
    "            if not isinstance(x, str):\n",
    "                return x\n",
    "            try:\n",
    "                if '억' in x:\n",
    "                    parts = x.split('억')\n",
    "                    if len(parts) == 2 and parts[1].strip():\n",
    "                        return int(parts[0].strip()) * 10000 + int(re.sub(r'[^\\d]', '', parts[1]))\n",
    "                    else:\n",
    "                        return int(parts[0].strip()) * 10000\n",
    "                else:\n",
    "                    return int(re.sub(r'[^\\d]', '', x))\n",
    "            except ValueError:\n",
    "                return x\n",
    "        \n",
    "        if kind == 'article' :\n",
    "            df['floorInfo'] = df['floorInfo'].apply(lambda x : x+'층')\n",
    "            \n",
    "            df['dealOrWarrantPrc'] = df['dealOrWarrantPrc'].apply(convert_price)\n",
    "            df.to_csv(self.article_dir, encoding='cp949', index=False)\n",
    "        elif kind == 'trade' :\n",
    "            df['formattedPrice'] = df['formattedPrice'].apply(convert_price)\n",
    "            # for idx, row in df.iterrows():\n",
    "            #     area_no = row['areaNo']\n",
    "            #     pyeongs = land.str2dict(row['pyeongs'])\n",
    "            #     if str(area_no) in pyeongs:\n",
    "            #         df.at[idx, 'pyeong'] = pyeongs[str(area_no)]\n",
    "            df.to_csv(self.trade_dir, encoding='cp949', index=False)\n",
    "        elif kind == 'info' :\n",
    "            df.to_csv(self.info_dir, encoding='cp949', index=False)\n",
    "        else :\n",
    "            print(\"kind에 article, trade, info 중 하나를 넣으세요.\")\n",
    "        return df\n",
    "    \n",
    "    def load(self, kind) :\n",
    "        \n",
    "        if kind == 'article' :\n",
    "            df = pd.read_csv(self.article_dir, encoding='cp949', )\n",
    "        elif kind == 'trade' :\n",
    "            df =pd.read_csv(self.trade_dir, encoding='cp949', )\n",
    "        elif kind == 'info' :\n",
    "            df =pd.read_csv(self.info_dir, encoding='cp949', )\n",
    "        else :\n",
    "            print(\"kind에 article, trade, info 중 하나를 넣으세요.\")\n",
    "        return df\n",
    "        \n",
    "    \n",
    "    def get_dong(self, cortarNo =\"1120000000\") :\n",
    "        \"\"\"구 이하 동이름 가져오기\"\"\"\n",
    "        url = \"https://new.land.naver.com/api/regions/list\"\n",
    "        headers = {\n",
    "            \"Cookie\": \"NNB=FCKCGABYXJBGM; ASID=de6c8eec0000018fe0e3f4d60000005d; NAC=r45BBMwegqUeB; NACT=1; nhn.realestate.article.rlet_type_cd=A01; nhn.realestate.article.trade_type_cd=; nhn.realestate.article.ipaddress_city=1100000000; _fwb=61LHhDmgSVSDTIn6beSYcT.1719020991264; landHomeFlashUseYn=Y; page_uid=iFhWwdqVOsCssiyk1dGsssssskR-268088; _fwb=61LHhDmgSVSDTIn6beSYcT.1719020991264; REALESTATE=Sat%20Jun%2022%202024%2011%3A04%3A44%20GMT%2B0900%20(KST); wcs_bt=4f99b5681ce60:1719021885; BUC=fZZA8_pWVcDwPBsokKy-ABqKINLnOafN4vdJCZoIdxs=\",\n",
    "            \"Referer\": \"https://new.land.naver.com/complexes?ms=37.554416,127.0195285,17&a=APT:ABYG:JGC:PRE&e=RETAIL\",\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\"\n",
    "        }\n",
    "\n",
    "        params = {\n",
    "            \"cortarNo\": cortarNo\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        data = response.json()\n",
    "        cortar_list = [( region['cortarNo'], region['cortarName'],) for region in data['regionList']]\n",
    "        return cortar_list\n",
    "    \n",
    "    # 아파트 목록가져오기\n",
    "    def get_apts(self, cortarNo = \"1120011000\") :\n",
    "        \"\"\"동 이하 아파트 이름 가져오기\"\"\"\n",
    "\n",
    "        url = \"https://new.land.naver.com/api/regions/complexes\"\n",
    "        headers = {\n",
    "            \"Cookie\": \"NNB=FCKCGABYXJBGM; ASID=de6c8eec0000018fe0e3f4d60000005d; NAC=r45BBMwegqUeB; NACT=1; nhn.realestate.article.rlet_type_cd=A01; nhn.realestate.article.trade_type_cd=; nhn.realestate.article.ipaddress_city=1100000000; _fwb=61LHhDmgSVSDTIn6beSYcT.1719020991264; landHomeFlashUseYn=Y; page_uid=iFhWwdqVOsCssiyk1dGsssssskR-268088; _fwb=61LHhDmgSVSDTIn6beSYcT.1719020991264; REALESTATE=Sat%20Jun%2022%202024%2011%3A04%3A44%20GMT%2B0900%20(KST); wcs_bt=4f99b5681ce60:1719021885; BUC=fZZA8_pWVcDwPBsokKy-ABqKINLnOafN4vdJCZoIdxs=\",\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\"\n",
    "        }\n",
    "\n",
    "        params = {\n",
    "            \"cortarNo\": cortarNo,\n",
    "            \"realEstateType\": \"APT:PRE\",\n",
    "            \"order\": \"\"\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        data = response.json()\n",
    "        cortar_list = [( region['complexNo'], region['complexName'],) for region in data['complexList']]\n",
    "        return cortar_list\n",
    "\n",
    "    def get_apts_mult(self, districts) : \n",
    "        \"\"\"구 이하 아파트 이름 가져오기\"\"\"\n",
    "        results = []\n",
    "\n",
    "        for district in districts :\n",
    "            no_district, name_district = district[0], district[1]\n",
    "            \n",
    "            dongs = self.get_dong(no_district)\n",
    "\n",
    "            for dong in dongs : \n",
    "                no_dong, name_dong = dong[0], dong[1]\n",
    "\n",
    "                apts = self.get_apts(no_dong)\n",
    "\n",
    "                for apt in apts :\n",
    "                    no_apt, name_apt = apt[0], apt[1]\n",
    "                    results.append((no_district,name_district,no_dong,name_dong,no_apt,name_apt))\n",
    "        df = pd.DataFrame(results)\n",
    "        df.columns = ['cortarNo_district','cortarName_district','cortarName_dong','name_dong','complexNo','complexName']\n",
    "\n",
    "        return df\n",
    "    \n",
    "    # 매물조회\n",
    "    def apt_items(self, \n",
    "                  complexNo = 1147, \n",
    "                  tradeType = \"A1:B1\", \n",
    "                  areaNos = '',\n",
    "                  page = 1, \n",
    "                  rentPriceMin= 0,\n",
    "                  rentPriceMax= 900000000,\n",
    "                  priceMin= 0,\n",
    "                  priceMax= 900000000,\n",
    "                  areaMin= 0,\n",
    "                  areaMax= 900000000,\n",
    "                  oldBuildYears= \"\",\n",
    "                  recentlyBuildYears= \"\",\n",
    "                  minHouseHoldCount= \"\",\n",
    "                  maxHouseHoldCount= \"\",\n",
    "                  ) :\n",
    "        \"\"\"단일 물건에 대한 매물정보 (호가정보) 가져오기.\n",
    "        complexNo : 물건id\n",
    "        tradeType : A1(매매) | B1(전세)\n",
    "        areaNos : 미기재 시 전체 평수에 대해. 복수 선택은 :으로 이어붙임. (예시. 1:2)\n",
    "        page : scroll 에 따라 추가정보 호출.\"\"\"\n",
    "\n",
    "        url = f\"https://new.land.naver.com/api/articles/complex/{complexNo}\"\n",
    "        headers = {\n",
    "            \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IlJFQUxFU1RBVEUiLCJpYXQiOjE3MTkwMjQ2MTEsImV4cCI6MTcxOTAzNTQxMX0.x3jYojHGWB6R2BHcODH8LI4CaxaxyHdcHFucBFCIS0Y\",\n",
    "            \"Cookie\": \"NNB=FCKCGABYXJBGM; ASID=de6c8eec0000018fe0e3f4d60000005d; NAC=r45BBMwegqUeB; NACT=1; nhn.realestate.article.rlet_type_cd=A01; nhn.realestate.article.trade_type_cd=; nhn.realestate.article.ipaddress_city=1100000000; _fwb=61LHhDmgSVSDTIn6beSYcT.1719020991264; landHomeFlashUseYn=Y; page_uid=iFhWwdqVOsCssiyk1dGsssssskR-268088; _fwb=61LHhDmgSVSDTIn6beSYcT.1719020991264; REALESTATE=Sat%20Jun%2022%202024%2011%3A50%3A11%20GMT%2B0900%20(KST); wcs_bt=4f99b5681ce60:1719024611; BUC=Dwr5Ph9_Z0h12xcrVOHR5Bz1D2_7_i3ypl51m0vlbfk=\",\n",
    "            \"Referer\": \"https://new.land.naver.com/complexes/1147?ms=37.544731,126.9391515,17&a=APT:PRE&b=A1&e=RETAIL\",\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\"\n",
    "        }\n",
    "\n",
    "        params = {\n",
    "            \"realEstateType\": \"APT:PRE\",\n",
    "            \"tradeType\": tradeType,\n",
    "            \"tag\": \"::::::::\",\n",
    "            \"rentPriceMin\": rentPriceMin,\n",
    "            \"rentPriceMax\": rentPriceMax,\n",
    "            \"priceMin\": priceMin,\n",
    "            \"priceMax\": priceMax,\n",
    "            \"areaMin\": areaMin,\n",
    "            \"areaMax\": areaMax,\n",
    "            \"oldBuildYears\": oldBuildYears,\n",
    "            \"recentlyBuildYears\": recentlyBuildYears,\n",
    "            \"minHouseHoldCount\": minHouseHoldCount,\n",
    "            \"maxHouseHoldCount\": maxHouseHoldCount,\n",
    "            \"showArticle\": \"false\",\n",
    "            \"sameAddressGroup\": \"true\",\n",
    "            \"minMaintenanceCost\": \"\",\n",
    "            \"maxMaintenanceCost\": \"\",\n",
    "            \"priceType\": \"RETAIL\",\n",
    "            \"directions\": \"\",\n",
    "            \"page\": page,\n",
    "            \"complexNo\": complexNo,\n",
    "            \"buildingNos\": \"\",\n",
    "            \"areaNos\": areaNos,\n",
    "            \"type\": \"list\",\n",
    "            \"order\": \"rank\"\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        result = response.json()\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def apt_items_mult(self, \n",
    "                  complexNo = 1147, \n",
    "                  tradeType = \"A1:B1\", \n",
    "                  areaNos = '',\n",
    "                  page = 1, \n",
    "                  rentPriceMin= 0,\n",
    "                  rentPriceMax= 900000000,\n",
    "                  priceMin= 0,\n",
    "                  priceMax= 900000000,\n",
    "                  areaMin= 0,\n",
    "                  areaMax= 900000000,\n",
    "                  oldBuildYears= \"\",\n",
    "                  recentlyBuildYears= \"\",\n",
    "                  minHouseHoldCount= \"\",\n",
    "                  maxHouseHoldCount= \"\",\n",
    "                  sleep = 1,\n",
    "                merge = 'apts') :\n",
    "        \n",
    "        results = []\n",
    "        is_more_data = True\n",
    "        while is_more_data :\n",
    "            try:\n",
    "                raw_data = self.apt_items(\n",
    "                    complexNo = complexNo,\n",
    "                    tradeType = tradeType,\n",
    "                    areaNos = areaNos,\n",
    "                    page = page,\n",
    "                    rentPriceMin = rentPriceMin,\n",
    "                    rentPriceMax = rentPriceMax,\n",
    "                    priceMin = priceMin,\n",
    "                    priceMax = priceMax,\n",
    "                    areaMin = areaMin,\n",
    "                    areaMax = areaMax,\n",
    "                    oldBuildYears = oldBuildYears,\n",
    "                    recentlyBuildYears = recentlyBuildYears,\n",
    "                    minHouseHoldCount = minHouseHoldCount,\n",
    "                    maxHouseHoldCount = maxHouseHoldCount,\n",
    "                )\n",
    "\n",
    "                if merge == 'apts_info' :\n",
    "                    result = self.apts_info[self.apts['complexNo'] == complexNo].to_dict()  # 기존 row의 데이터 포함\n",
    "                elif merge == 'apts' : \n",
    "                    result = self.apts[self.apts['complexNo'] == complexNo].to_dict()  # 기존 row의 데이터 포함\n",
    "                else :\n",
    "                    result = pd.DataFrame()\n",
    "\n",
    "                is_more_data = raw_data['isMoreData']\n",
    "                for article in raw_data['articleList'] :\n",
    "                    for col in self.cols_article :\n",
    "                        if col in article :\n",
    "                            result[col] = article[col]\n",
    "                    \n",
    "                    results.append(copy.deepcopy(result))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching data for complexNo {complexNo} and areaNo {areaNos}: {e}\")\n",
    "                is_more_data = False\n",
    "            \n",
    "            page += 1 \n",
    "            time.sleep(sleep)\n",
    "        return results\n",
    "\n",
    "\n",
    "    # 단지정보\n",
    "    def apt_info(self, complexNo = 1147, merge = True) :\n",
    "        \"\"\"단지정보 조회\"\"\"\n",
    "        url = f\"https://new.land.naver.com/api/complexes/overview/{complexNo}\"\n",
    "        headers = {\n",
    "            \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IlJFQUxFU1RBVEUiLCJpYXQiOjE3MTkwMjUyNDAsImV4cCI6MTcxOTAzNjA0MH0.ld0GtF1d0IZK-kDSqcmFarUz00qPN7g-7i_J5RpgTDY\",\n",
    "            \"Cookie\": \"NNB=FCKCGABYXJBGM; ASID=de6c8eec0000018fe0e3f4d60000005d; NAC=r45BBMwegqUeB; NACT=1; nhn.realestate.article.rlet_type_cd=A01; nhn.realestate.article.trade_type_cd=; nhn.realestate.article.ipaddress_city=1100000000; _fwb=61LHhDmgSVSDTIn6beSYcT.1719020991264; landHomeFlashUseYn=Y; page_uid=iFhWwdqVOsCssiyk1dGsssssskR-268088; _fwb=61LHhDmgSVSDTIn6beSYcT.1719020991264; REALESTATE=Sat%20Jun%2022%202024%2012%3A00%3A40%20GMT%2B0900%20(KST); BUC=RCphcWIuUeinf-MgG0Dke4l0F8fEAWdtIj-xN1lIlTE=; wcs_bt=4f99b5681ce60:1719025241\",\n",
    "            \"Priority\": \"u=1, i\",\n",
    "            \"Referer\": \"https://new.land.naver.com/complexes?ms=37.544731,126.942547,17&a=APT:ABYG:JGC:PRE&b=A1&e=RETAIL\",\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\"\n",
    "        }\n",
    "\n",
    "        params = {\n",
    "            \"complexNo\": complexNo\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        raw_data = response.json()\n",
    "        if merge : \n",
    "            result = self.apts[self.apts['complexNo'] == complexNo]\n",
    "        else :\n",
    "            result = pd.DataFrame()\n",
    "\n",
    "        for col in self.cols_info :         \n",
    "            try :\n",
    "                result[col] = raw_data[col]\n",
    "            except Exception as e :\n",
    "                result[col] = ''\n",
    "                print(f\"at {list(apts['complexName'])[idx]}, error occured with column : {col}\")\n",
    "                continue\n",
    "        for col in self.cols_pyeongs : \n",
    "            pyeong_info = {}\n",
    "            for pyeong in raw_data[col] :\n",
    "                pyeong_info[pyeong['pyeongNo']] =  pyeong['exclusiveArea']        \n",
    "            str_result = json.dumps(pyeong_info)\n",
    "            result[col] = str_result\n",
    "\n",
    "        return result\n",
    "\n",
    "    \n",
    "    # 실거래가\n",
    "    def real_trade(self, complexNo=1147, areaNo=0, db = 'apts') :\n",
    "        \"\"\"아파트 특정 평수 실거래가 조회\"\"\"\n",
    "\n",
    "        url = f\"https://new.land.naver.com/api/complexes/{complexNo}/prices/real\"\n",
    "        headers = {\n",
    "            \"Accept\": \"*/*\",\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br, zstd\",\n",
    "            \"Accept-Language\": \"ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "            \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IlJFQUxFU1RBVEUiLCJpYXQiOjE3MTkwMjYwNzYsImV4cCI6MTcxOTAzNjg3Nn0.-ohhan7oQNVxYwRI3nmwcmE3JeyD3M-HkvPJVShbEu4\",\n",
    "            \"Cookie\": \"NNB=FCKCGABYXJBGM; ASID=de6c8eec0000018fe0e3f4d60000005d; NAC=r45BBMwegqUeB; NACT=1; nhn.realestate.article.rlet_type_cd=A01; nhn.realestate.article.trade_type_cd=; nhn.realestate.article.ipaddress_city=1100000000; _fwb=61LHhDmgSVSDTIn6beSYcT.1719020991264; landHomeFlashUseYn=Y; page_uid=iFhWwdqVOsCssiyk1dGsssssskR-268088; _fwb=61LHhDmgSVSDTIn6beSYcT.1719020991264; REALESTATE=Sat%20Jun%2022%202024%2012%3A14%3A36%20GMT%2B0900%20(KST); wcs_bt=4f99b5681ce60:1719026076; BUC=p18HRKA3Y0XSqzq3tugbJNgv64iu42F1PQpR6QUumsI=\",\n",
    "            \"Priority\": \"u=1, i\",\n",
    "            \"Referer\": \"https://new.land.naver.com/complexes/1147?ms=37.5404435,126.9390494,16&a=APT:ABYG:JGC:PRE&b=A1&e=RETAIL&ad=true\",\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\"\n",
    "        }\n",
    "\n",
    "        params = {\n",
    "            \"complexNo\": complexNo,\n",
    "            \"tradeType\": \"A1\",\n",
    "            \"year\": 5,\n",
    "            \"priceChartChange\": \"false\",\n",
    "            \"areaNo\": areaNo,\n",
    "            \"type\": \"table\"\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        raw_data = response.json()['realPriceOnMonthList'] \n",
    "\n",
    "        try:\n",
    "            if db == 'apts_info' :\n",
    "                result = self.apts_info[self.apts['complexNo'] == complexNo].iloc[0, :].to_dict()  # 기존 row의 데이터 포함\n",
    "            else : \n",
    "                result = self.apts[self.apts['complexNo'] == complexNo].iloc[0, :].to_dict()  # 기존 row의 데이터 포함\n",
    "            result['areaNo'] = areaNo\n",
    "\n",
    "            for month in raw_data :\n",
    "                for trade in month['realPriceList'] :\n",
    "                    for col in self.cols_trade:\n",
    "                        if col in trade:\n",
    "                            result[col] = trade[col]\n",
    "                    results.append(result.copy())\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for complexNo {complexNo} and areaNo {areaNo}: {e}\")\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def str2dict(self, data) :\n",
    "        return ast.literal_eval(data)\n",
    "    \n",
    "    def get_pyeongs(self, complexNo) :\n",
    "        pyeongs = self.apts_info[self.apts_info['complexNo'] == complexNo]['pyeongs'].values[0]\n",
    "        pyeongs = self.str2dict(pyeongs)\n",
    "        return pyeongs\n",
    "\n",
    "\n",
    "         \n",
    "\n",
    "    def real_trade_mult(self, complexNo, pyeongs,  db = 'apts') : \n",
    "        \"\"\"아파트 단위 실거래가 조사\"\"\"\n",
    "        results = []\n",
    "        for areaNo, pyeong in pyeongs.items():\n",
    "            try:\n",
    "                result = self.real_trade(complexNo=complexNo, areaNo=areaNo, db=db)\n",
    "                for idx in range(len(result)) :\n",
    "                    result[idx] = result[idx]['pyeong'] = pyeong\n",
    "                results.append(result.copy())\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching data for complexNo {complexNo} and areaNo {areaNo}: {e}\")\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class naver_fetch_articles(Naver_seoul_land) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.results = pd.DataFrame()\n",
    "    # todo : 셀레니움으로 header를 좀 가져와야한다.\n",
    "    def fetch(self, \n",
    "              complexNos = [1147, 119219], \n",
    "            #   complexNos = [1147], \n",
    "              tradeType = \"A1:B1\", \n",
    "              areaNos = '',\n",
    "              page = 1, \n",
    "              rentPriceMin= 0,\n",
    "              rentPriceMax= 900000000,\n",
    "              priceMin= 0,\n",
    "              priceMax= 900000000,\n",
    "              areaMin= 0,\n",
    "              areaMax= 900000000,\n",
    "              oldBuildYears= \"\",\n",
    "              recentlyBuildYears= \"\",\n",
    "              minHouseHoldCount= \"\",\n",
    "              maxHouseHoldCount= \"\",) : \n",
    "        \n",
    "        \n",
    "        for complexNo in complexNos : \n",
    "            \n",
    "            # 위치 가져오기\n",
    "            # apt = self.total_apts[self.total_apts['complexNo'] == complexNo]\n",
    "            \n",
    "            # info 가져오기\n",
    "            info = self.apt_info(\n",
    "                complexNo = complexNo\n",
    "            )\n",
    "            \n",
    "            # todo : result를 제거해야함\n",
    "            # 매물 가져오기\n",
    "            articles = self.apt_items_mult(\n",
    "                complexNo = complexNo, \n",
    "                tradeType = \"A1:B1\", \n",
    "                areaNos = '', # 아무것도 입력안하면은 전체가 뜬다.\n",
    "                page = 1, \n",
    "                rentPriceMin= 0,\n",
    "                rentPriceMax= 900000000,\n",
    "                priceMin= 0,\n",
    "                priceMax= 900000000,\n",
    "                areaMin= 0,\n",
    "                areaMax= 900000000,\n",
    "                oldBuildYears= \"\",\n",
    "                recentlyBuildYears= \"\",\n",
    "                minHouseHoldCount= \"\",\n",
    "                maxHouseHoldCount= \"\",)\n",
    "            articles = pd.DataFrame(articles)\n",
    "            \n",
    "            \n",
    "\n",
    "            # for col in apt.columns :\n",
    "            #     articles[col] = apt[col].values[0]\n",
    "            for col in info.columns :\n",
    "                articles[col] = info[col].values[0]\n",
    "                \n",
    "\n",
    "            self.results = pd.concat([self.results, articles])\n",
    "\n",
    "        return apt, info, articles, self.results\n",
    "            \n",
    "\n",
    "nf = naver_fetch_articles()\n",
    "apt, info, articles, nf.results = nf.fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provinceNo</th>\n",
       "      <th>provinceName</th>\n",
       "      <th>districtNo</th>\n",
       "      <th>districtName</th>\n",
       "      <th>dongNo</th>\n",
       "      <th>dongName</th>\n",
       "      <th>complexNo</th>\n",
       "      <th>realEstateType</th>\n",
       "      <th>complexName</th>\n",
       "      <th>complexLatitude</th>\n",
       "      <th>complexLongitude</th>\n",
       "      <th>complexTypeName</th>\n",
       "      <th>totalHouseHoldCount</th>\n",
       "      <th>totalDongCount</th>\n",
       "      <th>useApproveYmd</th>\n",
       "      <th>minArea</th>\n",
       "      <th>maxArea</th>\n",
       "      <th>pyeongs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1100000000</td>\n",
       "      <td>서울시</td>\n",
       "      <td>1168000000</td>\n",
       "      <td>강남구</td>\n",
       "      <td>1168010300</td>\n",
       "      <td>개포동</td>\n",
       "      <td>146479</td>\n",
       "      <td>APT</td>\n",
       "      <td>YH빌리지</td>\n",
       "      <td>37.478247</td>\n",
       "      <td>127.04667</td>\n",
       "      <td>아파트</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>20170908</td>\n",
       "      <td>33.02</td>\n",
       "      <td>36.32</td>\n",
       "      <td>{\"1\": \"26.38\", \"2\": \"27.48\", \"3\": \"28.24\", \"4\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   provinceNo provinceName  districtNo districtName      dongNo dongName  \\\n",
       "0  1100000000          서울시  1168000000          강남구  1168010300      개포동   \n",
       "\n",
       "   complexNo realEstateType complexName  complexLatitude  complexLongitude  \\\n",
       "0     146479            APT       YH빌리지        37.478247         127.04667   \n",
       "\n",
       "  complexTypeName  totalHouseHoldCount  totalDongCount useApproveYmd  minArea  \\\n",
       "0             아파트                   16               1      20170908    33.02   \n",
       "\n",
       "   maxArea                                            pyeongs  \n",
       "0    36.32  {\"1\": \"26.38\", \"2\": \"27.48\", \"3\": \"28.24\", \"4\"...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        146479\n",
       "1           881\n",
       "2        119219\n",
       "3        140057\n",
       "4        107513\n",
       "          ...  \n",
       "45584    102357\n",
       "45585     15192\n",
       "45586     15193\n",
       "45587     19559\n",
       "45588    115454\n",
       "Name: complexNo, Length: 45589, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf.apts['complexNo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provinceNo</th>\n",
       "      <th>provinceName</th>\n",
       "      <th>districtNo</th>\n",
       "      <th>districtName</th>\n",
       "      <th>dongNo</th>\n",
       "      <th>dongName</th>\n",
       "      <th>complexNo</th>\n",
       "      <th>realEstateType</th>\n",
       "      <th>complexName</th>\n",
       "      <th>complexLatitude</th>\n",
       "      <th>...</th>\n",
       "      <th>sameAddrCnt</th>\n",
       "      <th>sameAddrMaxPrc</th>\n",
       "      <th>sameAddrMinPrc</th>\n",
       "      <th>complexTypeName</th>\n",
       "      <th>totalHouseHoldCount</th>\n",
       "      <th>totalDongCount</th>\n",
       "      <th>useApproveYmd</th>\n",
       "      <th>minArea</th>\n",
       "      <th>maxArea</th>\n",
       "      <th>pyeongs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1100000000</td>\n",
       "      <td>서울시</td>\n",
       "      <td>1144000000</td>\n",
       "      <td>마포구</td>\n",
       "      <td>1144010800</td>\n",
       "      <td>대흥동</td>\n",
       "      <td>1147</td>\n",
       "      <td>APT</td>\n",
       "      <td>대흥태영(마포태영)</td>\n",
       "      <td>37.544731</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9억 2,000</td>\n",
       "      <td>9억 2,000</td>\n",
       "      <td>아파트</td>\n",
       "      <td>1992</td>\n",
       "      <td>16</td>\n",
       "      <td>19991120</td>\n",
       "      <td>83.98</td>\n",
       "      <td>142.97</td>\n",
       "      <td>{\"2\": \"59.4\", \"3\": \"84.77\", \"4\": \"114.93\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1100000000</td>\n",
       "      <td>서울시</td>\n",
       "      <td>1144000000</td>\n",
       "      <td>마포구</td>\n",
       "      <td>1144010800</td>\n",
       "      <td>대흥동</td>\n",
       "      <td>1147</td>\n",
       "      <td>APT</td>\n",
       "      <td>대흥태영(마포태영)</td>\n",
       "      <td>37.544731</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>17억 5,000</td>\n",
       "      <td>17억 5,000</td>\n",
       "      <td>아파트</td>\n",
       "      <td>1992</td>\n",
       "      <td>16</td>\n",
       "      <td>19991120</td>\n",
       "      <td>83.98</td>\n",
       "      <td>142.97</td>\n",
       "      <td>{\"2\": \"59.4\", \"3\": \"84.77\", \"4\": \"114.93\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1100000000</td>\n",
       "      <td>서울시</td>\n",
       "      <td>1144000000</td>\n",
       "      <td>마포구</td>\n",
       "      <td>1144010800</td>\n",
       "      <td>대흥동</td>\n",
       "      <td>1147</td>\n",
       "      <td>APT</td>\n",
       "      <td>대흥태영(마포태영)</td>\n",
       "      <td>37.544731</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8억 7,000</td>\n",
       "      <td>8억 7,000</td>\n",
       "      <td>아파트</td>\n",
       "      <td>1992</td>\n",
       "      <td>16</td>\n",
       "      <td>19991120</td>\n",
       "      <td>83.98</td>\n",
       "      <td>142.97</td>\n",
       "      <td>{\"2\": \"59.4\", \"3\": \"84.77\", \"4\": \"114.93\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1100000000</td>\n",
       "      <td>서울시</td>\n",
       "      <td>1144000000</td>\n",
       "      <td>마포구</td>\n",
       "      <td>1144010800</td>\n",
       "      <td>대흥동</td>\n",
       "      <td>1147</td>\n",
       "      <td>APT</td>\n",
       "      <td>대흥태영(마포태영)</td>\n",
       "      <td>37.544731</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6억 2,000</td>\n",
       "      <td>6억 2,000</td>\n",
       "      <td>아파트</td>\n",
       "      <td>1992</td>\n",
       "      <td>16</td>\n",
       "      <td>19991120</td>\n",
       "      <td>83.98</td>\n",
       "      <td>142.97</td>\n",
       "      <td>{\"2\": \"59.4\", \"3\": \"84.77\", \"4\": \"114.93\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1100000000</td>\n",
       "      <td>서울시</td>\n",
       "      <td>1144000000</td>\n",
       "      <td>마포구</td>\n",
       "      <td>1144010800</td>\n",
       "      <td>대흥동</td>\n",
       "      <td>1147</td>\n",
       "      <td>APT</td>\n",
       "      <td>대흥태영(마포태영)</td>\n",
       "      <td>37.544731</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>16억</td>\n",
       "      <td>16억</td>\n",
       "      <td>아파트</td>\n",
       "      <td>1992</td>\n",
       "      <td>16</td>\n",
       "      <td>19991120</td>\n",
       "      <td>83.98</td>\n",
       "      <td>142.97</td>\n",
       "      <td>{\"2\": \"59.4\", \"3\": \"84.77\", \"4\": \"114.93\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    provinceNo provinceName  districtNo districtName      dongNo dongName  \\\n",
       "46  1100000000          서울시  1144000000          마포구  1144010800      대흥동   \n",
       "47  1100000000          서울시  1144000000          마포구  1144010800      대흥동   \n",
       "48  1100000000          서울시  1144000000          마포구  1144010800      대흥동   \n",
       "49  1100000000          서울시  1144000000          마포구  1144010800      대흥동   \n",
       "50  1100000000          서울시  1144000000          마포구  1144010800      대흥동   \n",
       "\n",
       "    complexNo realEstateType complexName  complexLatitude  ...  sameAddrCnt  \\\n",
       "46       1147            APT  대흥태영(마포태영)        37.544731  ...            1   \n",
       "47       1147            APT  대흥태영(마포태영)        37.544731  ...            1   \n",
       "48       1147            APT  대흥태영(마포태영)        37.544731  ...            1   \n",
       "49       1147            APT  대흥태영(마포태영)        37.544731  ...            1   \n",
       "50       1147            APT  대흥태영(마포태영)        37.544731  ...            1   \n",
       "\n",
       "   sameAddrMaxPrc sameAddrMinPrc complexTypeName totalHouseHoldCount  \\\n",
       "46       9억 2,000       9억 2,000             아파트                1992   \n",
       "47      17억 5,000      17억 5,000             아파트                1992   \n",
       "48       8억 7,000       8억 7,000             아파트                1992   \n",
       "49       6억 2,000       6억 2,000             아파트                1992   \n",
       "50            16억            16억             아파트                1992   \n",
       "\n",
       "   totalDongCount  useApproveYmd minArea maxArea  \\\n",
       "46             16       19991120   83.98  142.97   \n",
       "47             16       19991120   83.98  142.97   \n",
       "48             16       19991120   83.98  142.97   \n",
       "49             16       19991120   83.98  142.97   \n",
       "50             16       19991120   83.98  142.97   \n",
       "\n",
       "                                       pyeongs  \n",
       "46  {\"2\": \"59.4\", \"3\": \"84.77\", \"4\": \"114.93\"}  \n",
       "47  {\"2\": \"59.4\", \"3\": \"84.77\", \"4\": \"114.93\"}  \n",
       "48  {\"2\": \"59.4\", \"3\": \"84.77\", \"4\": \"114.93\"}  \n",
       "49  {\"2\": \"59.4\", \"3\": \"84.77\", \"4\": \"114.93\"}  \n",
       "50  {\"2\": \"59.4\", \"3\": \"84.77\", \"4\": \"114.93\"}  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.concat([nf.results, nf.results])\n",
    "print(len(a))\n",
    "print(len(nf.results))\n",
    "a.head()\n",
    "a.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([146479,    881], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf.total_apts['complexNo'].values[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(apt.columns)\n",
    "print(info.columns)\n",
    "print(articles.columns)\n",
    "# print(nf.resu.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import time\n",
    "    import random\n",
    "\n",
    "\n",
    "\n",
    "    시도단위들 = get_districts()['regionList']\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for 시도단위 in 시도단위들 :\n",
    "        시도단위id = 시도단위['cortarNo']\n",
    "        시도단위이름 = 시도단위['cortarName']\n",
    "        time.sleep(random.randint(1, 5))\n",
    "        자치구들 = get_small_districts(시도단위id)['regionList']\n",
    "        for 자치구 in 자치구들 : \n",
    "            자치구id = 자치구['cortarNo']\n",
    "            자치구이름 = 자치구['cortarName']\n",
    "            time.sleep(random.randint(1, 5))\n",
    "            동읍면들 = get_dong(자치구id)['regionList']\n",
    "            for 동읍면 in 동읍면들 : \n",
    "                동읍면id = 동읍면['cortarNo']\n",
    "                동읍면이름 = 동읍면['cortarName']\n",
    "                time.sleep(random.randint(1, 5))\n",
    "                건물들 = get_apts(동읍면id)['complexList']\n",
    "                for 건물 in 건물들 : \n",
    "                    건물id = 건물['complexNo']\n",
    "                    건물이름 = 건물['complexName']\n",
    "                    건물타입 = 건물['realEstateTypeCode']\n",
    "                    위도 = 건물['latitude']\n",
    "                    경도 = 건물['longitude']\n",
    "                    result = (시도단위id, 시도단위이름, 자치구id, 자치구이름, 동읍면id, 동읍면이름, 건물id, 건물타입, 건물이름, 위도, 경도)\n",
    "                    results.append(result)\n",
    "                    print(result)\n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cols = [시도단위id, 시도단위이름, 자치구id, 자치구이름, 동읍면id, 동읍면이름, 건물id, 건물타입, 건물이름, 위도, 경도]\n",
    "cols = [\n",
    "    \"provinceNo\",\n",
    "    \"provinceName\",\n",
    "    \"districtNo\",\n",
    "    \"districtName\",\n",
    "    \"dongNo\",\n",
    "    \"dongName\",\n",
    "    \"complexNo\",\n",
    "    \"realEstateType\",\n",
    "    \"complexName\",\n",
    "    \"complexLatitude\",\n",
    "    \"complexLongitude\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(results, columns=cols)\n",
    "import os\n",
    "df.to_csv(os.path.join('부동산','전국.csv'), encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "\n",
    "land = Naver_seoul_land() \n",
    "sample = 1\n",
    "districts = ['동대문구', '영등포구']\n",
    "\n",
    "for district in districts :\n",
    "    land.config_district(district)\n",
    "\n",
    "    # 부동산정보수집\n",
    "    results=[]\n",
    "    for complexNo in  land.apts['complexNo'] :        \n",
    "        time.sleep(1.5)\n",
    "        results.append(land.apt_info(complexNo))\n",
    "    df = land.save(results, kind='info')\n",
    "    land.renew()\n",
    "    print('[SYSTEM] 정보수집완료')\n",
    "    \n",
    "\n",
    "    # 매물조사\n",
    "    results = []\n",
    "    for complexNo in  land.apts['complexNo'] :        \n",
    "        time.sleep(1.5)\n",
    "        results += land.apt_items_mult(complexNo, db='apts_info')\n",
    "    df2 = land.save(results, kind='article')\n",
    "    land.renew()\n",
    "    print('[SYSTEM] 매물수집완료')\n",
    "    \n",
    "    # 실거래가\n",
    "    results = []\n",
    "    for complexNo in  land.apts['complexNo'] :        \n",
    "        # time.sleep(1.5)\n",
    "        pyeongs = land.get_pyeongs(complexNo)\n",
    "        results += land.real_trade_mult(complexNo, pyeongs, db='apts_info')\n",
    "    df3 = land.save(results, kind='trade')\n",
    "    land.renew()\n",
    "    print('[SYSTEM] 실거래가 수집완료')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "\n",
    "base = '부동산'\n",
    "items = os.listdir(base)\n",
    "# 폴더인지 확인하고 '서울.csv'를 제외한 목록에서 폴더만 추출\n",
    "mydistricts = [item for item in items if os.path.isdir(os.path.join(base, item)) and item != '서울.csv']\n",
    "\n",
    "\n",
    "dfs = []\n",
    "dfs_info = []\n",
    "dfs_trade = []\n",
    "dfs_article = []\n",
    "\n",
    "for mydistrict in mydistricts :\n",
    "    dfa = pd.read_csv(os.path.join(base, mydistrict, f'{mydistrict}.csv'), encoding='cp949')\n",
    "    dfa_info = pd.read_csv(os.path.join(base, mydistrict, f'{mydistrict}_정보.csv'), encoding='cp949')\n",
    "    dfa_trade = pd.read_csv(os.path.join(base, mydistrict, f'{mydistrict}_실거래.csv'), encoding='cp949')\n",
    "    dfa_article = pd.read_csv(os.path.join(base, mydistrict, f'{mydistrict}_매물.csv'), encoding='cp949')\n",
    "\n",
    "    print(dfa.columns)\n",
    "    print(dfa_info.columns)\n",
    "    print(dfa_trade.columns)\n",
    "    print(dfa_article.columns)\n",
    "    print('💛')\n",
    "\n",
    "\n",
    "    dfs.append(copy.deepcopy(dfa))\n",
    "    dfs_info.append(copy.deepcopy(dfa_info))\n",
    "    dfs_trade.append(copy.deepcopy(dfa_trade))\n",
    "    dfs_article.append(copy.deepcopy(dfa_article))\n",
    "\n",
    "\n",
    "base_df = pd.DataFrame()\n",
    "base_df_info = pd.DataFrame()\n",
    "base_df_trade = pd.DataFrame()\n",
    "base_df_article = pd.DataFrame()\n",
    "\n",
    "for idx in range(len(dfs)) :\n",
    "    base_df = pd.concat([base_df, dfs[idx]], ignore_index=True)\n",
    "    base_df_info = pd.concat([base_df_info, dfs_info[idx]], ignore_index=True)\n",
    "    base_df_trade = pd.concat([base_df_trade, dfs_trade[idx]], ignore_index=True)\n",
    "    base_df_article = pd.concat([base_df_article, dfs_article[idx]], ignore_index=True)\n",
    "\n",
    "\n",
    "base_df.to_csv(os.path.join(base, '서대문동대문성동구영등포마포.csv'), encoding='cp949', index=False)\n",
    "base_df_info.to_csv(os.path.join(base, '서대문동대문성동구영등포마포_정보.csv'), encoding='cp949', index=False)\n",
    "base_df_trade.to_csv(os.path.join(base, '서대문동대문성동구영등포마포_실거래.csv'), encoding='cp949', index=False)\n",
    "base_df_article.to_csv(os.path.join(base, '서대문동대문성동구영등포마포_매물.csv'), encoding='cp949', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_price(x):\n",
    "    if isinstance(x, int):\n",
    "        return x * 10000 if x <= 100 else x\n",
    "    if not isinstance(x, str):\n",
    "        return x\n",
    "    try:\n",
    "        if '억' in x:\n",
    "            parts = x.split('억')\n",
    "            if len(parts) == 2 and parts[1].strip():\n",
    "                return int(parts[0].strip()) * 10000 + int(re.sub(r'[^\\d]', '', parts[1]))\n",
    "            else:\n",
    "                return int(parts[0].strip()) * 10000\n",
    "        else:\n",
    "            return int(re.sub(r'[^\\d]', '', x))\n",
    "    except ValueError:\n",
    "        return x\n",
    "\n",
    "base = '부동산'\n",
    "items = os.listdir(base)\n",
    "mydistricts = [item for item in items if os.path.isdir(os.path.join(base, item)) and item != '서울.csv']\n",
    "\n",
    "for mydistrict in mydistricts:\n",
    "    path = os.path.join(base, mydistrict, f'{mydistrict}_매물.csv')\n",
    "    df = pd.read_csv(path, encoding='cp949')\n",
    "\n",
    "    df['dealOrWarrantPrc'] = df['sameAddrMaxPrc'].apply(convert_price)\n",
    "    \n",
    "    df.to_csv(path, index=False, encoding='cp949')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 호갱노노\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import fnmatch\n",
    "import time\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "# from seleniumwire import webdriver  # selenium-wire를 사용합니다.\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import clear_output\n",
    "import copy\n",
    "\n",
    "\n",
    "class Hogangnono:\n",
    "    def __doc__(self) :\n",
    "        print(\"\"\"\n",
    "    이 클래스는 호갱노노 웹사이트를 크롤링합니다.\n",
    "\n",
    "    구조체설명:\n",
    "              - 기본적으로 apt_id와 areaNo, name를 기반으로 작동합니다.\n",
    "              - 아무것도 입력하지 않으면 서울 전체 지역에 대해서 작동합니다.\n",
    "              - id, 동, 구, 시를 입력할 수 있도록 만들어야 합니다.\n",
    "              - 현재는 id에 대해서 모든 것이 정립된 상황이라 생각하시면 되겠습니다.\n",
    "              - 이후의 내용에 대해서는 반복문을 통해서 할 수 있습니다.\n",
    "    \n",
    "    주요 기능:\n",
    "    - DB) 지역의 아파트 목록을 가져올 수 있습니다.\n",
    "    - 메인1) 아파트의 자세한 정보(INFO)를 가져올 수 있습니다.\n",
    "    - 메인2) 아파트의 실거래가(REAL_TRADE)를 가져올 수 있습니다.\n",
    "              \n",
    "    - 서브1) 수집된 데이터를 CSV 파일로 저장합니다.\n",
    "    - 서브2) 수집된 데이터를 병합하고 통합된 파일을 생성합니다.\n",
    "    \n",
    "    - 참고) 날짜 범위를 설정하여 실거래가 데이터를 선형 보간법을 사용해 보정합니다.\n",
    "              (보간법 -> ffill(미래데이터추정) -> bfill(과거데이터가져오기))\n",
    "\n",
    "    주요 속성:\n",
    "    - root_folder: 데이터를 저장할 루트 폴더 경로\n",
    "    - real_trade_folder: 실거래가 데이터를 저장할 폴더 경로\n",
    "    \n",
    "    - apts_path: 아파트 정보를 저장할 CSV 파일 경로\n",
    "    - info_path: 아파트 상세 정보를 저장할 CSV 파일 경로\n",
    "    - real_trade_path: 실거래가 데이터를 저장할 CSV 파일 경로\n",
    "    - filled_real_trade_path: 보정된 실거래가 데이터를 저장할 CSV 파일 경로\n",
    "    - merge_apts_info_path: 아파트 정보와 상세 정보를 병합한 CSV 파일 경로\n",
    "    - merge_apts_info_real_trade_path: 모든 데이터를 병합한 CSV 파일 경로\n",
    "    - merge_apts_info_filled_real_trade_path: 보간법 적용 실거래가 데이터를 병합한 CSV 파일 경로\n",
    "              \n",
    "    - date_list: 데이터 수집 날짜 목록\n",
    "\n",
    "    주요 메서드:\n",
    "    - ✅__init__: 클래스 초기화 및 폴더 생성\n",
    "    - config: 수집할 지역 설정\n",
    "    - get_all_datas: 모든 데이터 로드\n",
    "    - get_filenames: 파일 목록 가져오기\n",
    "    - fetch_real_trade_data_one_time: 특정면적 최초 10개 실거래가 데이터 가져오기\n",
    "    - fetch_real_trade_data_single_areaNo: 특정 면적의 실거래가 데이터 수집\n",
    "    - fetch_real_trade_data_single_id: 특정 아파트의 실거래가 데이터 수집\n",
    "    - get_dates: 날짜 목록 생성\n",
    "    - open_json_file: JSON 파일 열기\n",
    "    - formatting_date: 날짜 형식 변환\n",
    "    - get_apts_info: 아파트 정보 가져오기\n",
    "    - fill_apts_info: 아파트 정보 채우기\n",
    "    - fill_trade_data: 실거래가 데이터 보정\n",
    "    - get_trade_data: 실거래가 데이터 가져오기\n",
    "    - main: 가격정보를 모아주는 메서드 \n",
    "    - merge_real_trades: 실거래가 데이터 병합\n",
    "    - extract_data_from_raw_json: 원본 JSON 데이터에서 정보 추출\n",
    "    - fetch_apt_info: 아파트 상세 정보 수집\n",
    "    - merge: 모든 데이터 병합  \n",
    "\n",
    "              TODO1) 캐싱 | INFO의 경우에는 캐싱해도 된다.\n",
    "              TODO2) 매물 | 네이버지도에서 가져오면 된다.\n",
    "              TODO3) GUI  | 만들어서 팔자.\n",
    "              TODO4) HEADER  | SELENIUM 이용해서 HEADER 갱신이 필요\n",
    "              \n",
    "              \"\"\")\n",
    "\n",
    "    def __init__(self):\n",
    "        # 폴더경로\n",
    "        self.root_folder = '호갱노노'\n",
    "        self.data_folder = os.path.join(self.root_folder, 'data')\n",
    "        self.info_folder = os.path.join(self.data_folder, 'info')\n",
    "        self.real_trade_folder = os.path.join(self.data_folder, 'real_trade')\n",
    "\n",
    "        # 폴더가 없으면 생성\n",
    "        os.makedirs(self.root_folder, exist_ok=True)\n",
    "        os.makedirs(self.data_folder, exist_ok=True)\n",
    "        os.makedirs(self.info_folder, exist_ok=True)\n",
    "        os.makedirs(self.real_trade_folder, exist_ok=True)\n",
    "\n",
    "        # 단일파일경로\n",
    "        self.apts_path = os.path.join(self.data_folder, '호갱노노.csv')\n",
    "        self.info_path = os.path.join(self.root_folder, '호갱노노_정보.csv') \n",
    "        self.real_trade_path = os.path.join(self.root_folder, '호갱노노_실거래가.csv')        \n",
    "        self.filled_real_trade_path = os.path.join(self.root_folder, '호갱노노_실거래가_선형보간.csv')        \n",
    "\n",
    "        # 합친파일경로        \n",
    "        self.merge_apts_info_path = os.path.join(self.root_folder, '호갱노노_통합.csv') \n",
    "        self.merge_apts_info_real_trade_path = os.path.join(self.root_folder, '호갱노노_완전체.csv') \n",
    "        self.merge_apts_info_filled_real_trade_path = os.path.join(self.root_folder, '호갱노노_완전체_선형보간.csv') \n",
    "        \n",
    "\n",
    "\n",
    "        # 필요한 변수들.\n",
    "        self.date_list = self.get_dates()\n",
    "        self.get_all_datas()\n",
    "    \n",
    "    # def save_all_data(self) ;\n",
    "    \"\"\"다 저장하도록 해야함.\"\"\"\n",
    "\n",
    "    def config(self, districts='all') :\n",
    "        if type(districts) == str :\n",
    "            districts = list(districts)\n",
    "        elif type(districts) != list :\n",
    "            print('district를 올바르게 설정하세요')\n",
    "            return\n",
    "\n",
    "        \n",
    "        \n",
    "    def load_csv(self, file_path):\n",
    "        if os.path.exists(file_path):\n",
    "            return pd.read_csv(file_path, encoding='cp949')\n",
    "        else:\n",
    "            return pd.DataFrame()  # Return an empty DataFrame if the file does not exist \n",
    "    def save_csv(self, data, file_path, encoding='cp949', errors='replace', index=False) :\n",
    "        data.to_csv(file_path, encoding=encoding, errors=errors, index=index)\n",
    "\n",
    "    def get_all_datas(self):\n",
    "        self.apts = self.load_csv(self.apts_path)\n",
    "        self.info = self.load_csv(self.info_path)\n",
    "        self.real_trade = self.load_csv(self.real_trade_path)\n",
    "        self.filled_real_trade = self.load_csv(self.filled_real_trade_path)\n",
    "        self.merge_apts_info = self.load_csv(self.merge_apts_info_path)\n",
    "        self.merge_apts_info_real_trade = self.load_csv(self.merge_apts_info_real_trade_path)\n",
    "        self.merge_apts_info_filled_real_trade = self.load_csv(self.merge_apts_info_filled_real_trade_path)\n",
    "\n",
    "\n",
    "\n",
    "    def get_filenames(self, type='info') :\n",
    "        if type == 'info' :\n",
    "            return [name for name in os.listdir(self.root_folder) if '.json' in name]\n",
    "        if type == 'trade' :\n",
    "            return [name for name in os.listdir(self.real_trade_folder) if '.json' in name]\n",
    "\n",
    "    def fetch_real_trade_data_one_time(self, apt_id, areaNo, start):\n",
    "        cookies = {\n",
    "            'bat': 'B-VEzEDDnAr6CcP6k_SI0s2QqZ78PHXDpJkw',\n",
    "            '_gcl_au': '1.1.1543066674.1719753966',\n",
    "            '_fbp': 'fb.1.1719753965794.820917726471047565',\n",
    "            '_gid': 'GA1.2.18808630.1719753966',\n",
    "            '_wp_uid': '1-821aee09be2ee8d0af9029b7e4a8355c-s1711704073.904983|windows_10|chrome-2ui902',\n",
    "            'connect.sid': 's%3AH3Hg--8KIBQ_kT2unBOECRwPC4bCysN_2Q.ocLMX3yyzVCAzhppmZYPiRkGyZyJYlwNYgUEdBkcEKM',\n",
    "            '_ga': 'GA1.1.1496764594.1719753966',\n",
    "            'cto_bundle': 'ypfqWF84WlQwJTJCZTBFYUZ4RlglMkJQdXJhMCUyQjRhTjFERmR0bmo5Rm4yaWgyOFY5JTJCUERHcFpDZ2hEWXdpJTJGcENROFVNJTJGNzRtMiUyRnU2TWxEcElVRThKRTBXS3kzYko4eWowbFB0cEdTJTJCd2lOQ09WRWc3Nkpma2JiNE5LZEMzOGFZZnFXdDJzNXJlNnA5Um1IcURsSzY5V04lMkZBVHRFYXJtOURxZ2hXUEMwdlk2WUVFVURqNGtFbVZYejFtS3pVb3ZLZEtVU1ZKZmZ4UEpBM3hIJTJGNVdTZSUyQjFJdVRtU25SdyUzRCUzRA',\n",
    "            '_ga_P8RWS72S79': 'GS1.1.1719883930.11.1.1719884250.0.0.0',\n",
    "            'client.cid': 'JngTZb5cTiCB4vmgIUgcl4OTzYZPexzKtahKl9MjHss',\n",
    "        }\n",
    "\n",
    "        headers = {\n",
    "            'accept': 'application/json',\n",
    "            'accept-language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "            'priority': 'u=1, i',\n",
    "            'referer': 'https://hogangnono.com/apt/1VO56/0/2',\n",
    "            'sec-ch-ua': '\"Not/A)Brand\";v=\"8\", \"Chromium\";v=\"126\", \"Google Chrome\";v=\"126\"',\n",
    "            'sec-ch-ua-mobile': '?0',\n",
    "            'sec-ch-ua-platform': '\"Windows\"',\n",
    "            'sec-fetch-dest': 'empty',\n",
    "            'sec-fetch-mode': 'cors',\n",
    "            'sec-fetch-site': 'same-origin',\n",
    "            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36',\n",
    "            'x-hogangnono-api-version': '1.9.18',\n",
    "            'x-hogangnono-app-name': 'hogangnono',\n",
    "            'x-hogangnono-at': 'B-VEzEDDnAr6CcP6k_SI0s2QqZ78PHXDpJkw',\n",
    "            'x-hogangnono-ct': '1719884523578',\n",
    "            'x-hogangnono-event-duration': '890477',\n",
    "            'x-hogangnono-event-log': '620f9c27023d936e8feeec11e3efcadd867fed90',\n",
    "            'x-hogangnono-platform': 'desktop',\n",
    "            'x-hogangnono-release-version': '1.9.18.14',\n",
    "        }\n",
    "\n",
    "        params = {\n",
    "            'tradeType': '0',\n",
    "            'areaNo': areaNo,\n",
    "            'start': start,\n",
    "        }\n",
    "\n",
    "        response = requests.get(f'https://hogangnono.com/api/v2/apts/{apt_id}/trade-real', params=params, cookies=cookies, headers=headers)\n",
    "        return response.json()\n",
    "    \n",
    "    def fetch_real_trade_data_single_areaNo(self, apt_id, areaNo=None):\n",
    "        real_trades = []\n",
    "        isEnd = False\n",
    "        start = 0\n",
    "\n",
    "        while not isEnd:     \n",
    "            data = self.fetch_real_trade_data_one_time(apt_id, areaNo, start)\n",
    "            \n",
    "            if data['data']:\n",
    "                isEnd = data['data']['isEnd']\n",
    "                real_trades += data['data']['data']\n",
    "                print(start, isEnd)\n",
    "            else:\n",
    "                return\n",
    "            \n",
    "            if not isEnd:\n",
    "                start += 10\n",
    "                continue\n",
    "            elif isEnd:\n",
    "                return real_trades\n",
    "            \n",
    "    def fetch_real_trade_data_single_id(self, apt_id, apt_name):\n",
    "        \"\"\"핵심기능1) 실거래가를 조회한다.\"\"\"\n",
    "        wrongAreaNo = False\n",
    "        areaNo = None\n",
    "        while not wrongAreaNo:\n",
    "            real_trades = self.fetch_real_trade_data_single_areaNo(apt_id, areaNo)\n",
    "            if real_trades:\n",
    "                if areaNo == None :\n",
    "                    areaNo = 0\n",
    "                with open(os.path.join(self.real_trade_folder, f'{apt_id}_{apt_name}_{areaNo}.json'), 'w', encoding='utf-8') as json_file:\n",
    "                    json.dump(real_trades, json_file, ensure_ascii=False, indent=4)\n",
    "                if areaNo :\n",
    "                    areaNo += 1\n",
    "                else : areaNo = 1\n",
    "\n",
    "            else:\n",
    "                wrongAreaNo = True\n",
    "\n",
    "    def get_dates(self, start_date=\"2005-12\", end_date=\"2024-06\"):\n",
    "        date_range = pd.date_range(start=start_date, end=end_date, freq='MS')\n",
    "        date_list = date_range.strftime('%Y-%m').tolist()\n",
    "        return date_list\n",
    "\n",
    "    def open_json_file(self, file_path, encoding='utf-8'):\n",
    "        with open(file_path, 'r', encoding=encoding) as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "\n",
    "    def formatting_date(self, date_str, format_from='%Y-%m-%dT%H:%M:%S.%fZ', format_to='%Y-%m'):\n",
    "        formatted_date = datetime.strptime(date_str, format_from).strftime(format_to)\n",
    "        return formatted_date\n",
    "\n",
    "    def get_apts_info(self):\n",
    "        df = pd.read_csv(self.apts_path, encoding='cp949', index_col=0)\n",
    "        self.apts_info = df\n",
    "        return df\n",
    "    \n",
    "    def fill_apts_info(self, df):\n",
    "        def splitting(data) :\n",
    "            splitted = data.split('_')\n",
    "            return splitted[0], splitted[1]\n",
    "        ids = list(df.index)\n",
    "        results = list(map(splitting, list(ids)))\n",
    "\n",
    "        ids = []\n",
    "        areaNo = []\n",
    "        area = []\n",
    "        for result in results:\n",
    "            ids.append( result[0])\n",
    "            areaNo.append( result[1])\n",
    "\n",
    "        cols = self.apts_info.columns\n",
    "        for col in cols:\n",
    "            datas = []\n",
    "            for id in ids:\n",
    "                datas.append(self.apts_info[self.apts_info['id'] == id][col].values[0])\n",
    "            try:\n",
    "                df.insert(1, col, datas)\n",
    "            except:\n",
    "                continue\n",
    "        return df\n",
    "    def fill_trade_data(self) :\n",
    "        df = pd.read_csv(os.path.join(path, '통합본.csv'), index_col=0)\n",
    "        df_filled = df.ffill(axis=1)\n",
    "        df_filled = df_filled.bfill(axis=1)\n",
    "\n",
    "        return df_filled\n",
    "\n",
    "\n",
    "    \n",
    "    def get_trade_data(self, filenames):\n",
    "        total = len(filenames)\n",
    "        now = 0\n",
    "        df = pd.DataFrame(columns=['areaType'] + self.date_list)\n",
    "        \n",
    "        for filename in filenames:\n",
    "            now += 1\n",
    "            \n",
    "            print(f'{now}/{total}')\n",
    "            if now  % 10 == 0 : clear_output()\n",
    "            name = filename.replace('.json', '')\n",
    "            data = self.open_json_file(os.path.join(self.real_trade_folder, filename))\n",
    "            \n",
    "            max_prices = {}\n",
    "            for trade in data:\n",
    "                result = {\n",
    "                    \"floor\": trade['floor'],\n",
    "                    \"date\": self.formatting_date(trade['date']),\n",
    "                    \"areaType\": trade['areaType'],\n",
    "                    'dong': trade['dong'],\n",
    "                    'price': trade['price'],\n",
    "                }\n",
    "                current_price = max_prices.get(result['date'], 0)\n",
    "                if result['price'] > current_price:\n",
    "                    max_prices[result['date']] = result['price']\n",
    "            for date, price in max_prices.items():\n",
    "                df.at[name, date] = price\n",
    "                df.at[name, 'areaType' ]= result['areaType']\n",
    "                \n",
    "            if now < 5:\n",
    "                print(data)\n",
    "                display(df.head())            \n",
    "            \n",
    "            # areaType 칼럼을 조정합니다.\n",
    "            df['areaType'] = df['areaType'].apply(lambda x : x.split('/')[0])\n",
    "            def extract_number(item):\n",
    "                return re.split('[^0-9]', item)[0]\n",
    "            df['areaType'] = df['areaType'].apply(extract_number)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "        \n",
    "    def main(self):\n",
    "        filenames = fnmatch.filter(os.listdir(self.real_trade_folder), '*.json')\n",
    "        df = self.get_trade_data(filenames)\n",
    "        df = df.reset_index()\n",
    "        cols = list(df.columns)\n",
    "        cols[0] = 'id_areaNo'\n",
    "        df.columns = cols\n",
    "        # 'id_areaNo' 열의 값을 '_' 기준으로 분리하여 'id'와 'areaNo' 열을 만듭니다.\n",
    "        df[['id', 'name', 'areaNo']] = df['id_areaNo'].str.split('_', expand=True)\n",
    "        # 'id' 열을 1번째에, 'areaNo' 열을 2번째에 삽입합니다.\n",
    "        df = df[['id', 'name','areaNo'] + [col for col in df.columns if col not in ['id', 'areaNo', 'id_areaNo']]]\n",
    "        # 기본 파일 저장\n",
    "        df.to_csv(self.real_trade_path, encoding='cp949', index=False)\n",
    "        # 채워 넣은 파일 저장 (선형보간법)\n",
    "        try :\n",
    "            df[self.date_list] = df[self.date_list].apply(pd.to_numeric, errors='coerce')\n",
    "            df[self.date_list] = df[self.date_list].interpolate(axis=1, limit_area='inside')\n",
    "            df.to_csv(self.filled_real_trade_path, encoding='cp949', index=False)\n",
    "        except Exception as e :\n",
    "            print(e)\n",
    "        return df\n",
    "\n",
    "\n",
    "    def merge_real_trades(self) :\n",
    "        filenames = fnmatch.filter(os.listdir(self.real_trade_folder), '*.json')\n",
    "        total = len(filenames)\n",
    "        now = 0\n",
    "        df = pd.DataFrame(columns=self.date_list)\n",
    "\n",
    "        for filename in filenames :\n",
    "            now += 1 \n",
    "            print(f'{now}/{total}')\n",
    "            name = filename.replace('.json', '')\n",
    "            data = self.open_json_file(os.path.join(self.real_trade_folder, filename))  # Fix this line to use the correct filename\n",
    "            \n",
    "            # 가장 높은 가격을 저장할 딕셔너리\n",
    "            max_prices = {}\n",
    "            \n",
    "            for trade in data:\n",
    "                result = {\n",
    "                    \"floor\": trade['floor'],\n",
    "                    \"date\": self.formatting_date(trade['date']),\n",
    "                    \"areaType\": trade['areaType'],\n",
    "                    'dong': trade['dong'],\n",
    "                    'price': trade['price'],\n",
    "                }\n",
    "\n",
    "                # 기존 날짜의 가격과 비교하여 더 높은 가격을 저장\n",
    "                current_price = max_prices.get(result['date'], 0)\n",
    "                \n",
    "                if result['price'] > current_price:\n",
    "                    max_prices[result['date']] = result['price']\n",
    "\n",
    "            # DataFrame에 가장 높은 가격을 저장\n",
    "            for date, price in max_prices.items():\n",
    "                df.at[name, date] = price\n",
    "\n",
    "        # 최종 결과 출력\n",
    "        df.to_csv(os.path.join(self.real_trade_folder, '통합본.csv'))\n",
    "\n",
    "    def extract_data_from_raw_json(self, save=True):\n",
    "        directory = self.root_folder\n",
    "        filenames = [file for file in os.listdir(directory) if '.json' in file]\n",
    "        results = []\n",
    "        \n",
    "        subwaynames = [\n",
    "            \"1호선\", \"2호선\", \"3호선\", \"4호선\", \"5호선\",\n",
    "            \"6호선\", \"7호선\", \"8호선\", \"9호선\", \"신분당선\",\n",
    "            \"공항철도\", \"경의중앙선\", \"우이신설선\", \"경춘선\", \"수인분당선\",\n",
    "            \"경강선\"\n",
    "        ]\n",
    "        now = 0\n",
    "        total = len(filenames)\n",
    "        for filename in filenames:\n",
    "            now += 1\n",
    "            print(f'{now}/{total}')\n",
    "            if now % 20 == 0 : clear_output()   \n",
    "            data = self.open_json_file(os.path.join(directory, filename))['data']\n",
    "            result = {\n",
    "                'id' : data.get('id'),\n",
    "                'name': data.get('name'),\n",
    "                'trade_count': data.get('trade_count'),\n",
    "                'total_household': data.get('total_household'),\n",
    "                'manage_cost': data.get('baseinfo', {}).get('manage_cost', {}).get('year'),\n",
    "                'building_count': data.get('baseinfo', {}).get('building_count'),\n",
    "                'floor_max': data.get('baseinfo', {}).get('floor_max'),\n",
    "                'floor_min': data.get('baseinfo', {}).get('floor_min'),\n",
    "                'slope': data.get('baseinfo', {}).get('slope'),\n",
    "                'approval_date': data.get('baseinfo', {}).get('approval_date') or data.get('baseinfo', {}).get('permission_date'),\n",
    "                'parking_rate': data.get('baseinfo', {}).get('parking_rate'),\n",
    "                'earthquake': data.get('baseinfo', {}).get('earthquake'),\n",
    "                'nearby_school_point': data.get('nearby_school_point'),\n",
    "                'nearby_subway_station_count': data.get('nearby_subway_station_count'),\n",
    "                'total_rental_business_household': data.get('total_rental_business_household'),\n",
    "                'areas': [],\n",
    "                'subways': [],\n",
    "                'ktxs': [],\n",
    "                'park_name': data.get('convenience', {}).get('park', {}).get('nearBy', {}).get('name'),\n",
    "                'park_dist': data.get('convenience', {}).get('park', {}).get('nearBy', {}).get('dist'),\n",
    "                'mart_name': data.get('convenience', {}).get('mart', [{}])[0].get('name'),\n",
    "                'mart_dist': data.get('convenience', {}).get('mart', [{}])[0].get('dist'),\n",
    "                'hospital_name': data.get('convenience', {}).get('hospital', [{}])[0].get('name'),\n",
    "                'hospital_dist': data.get('convenience', {}).get('hospital', [{}])[0].get('dist'),\n",
    "                'elementarySchool_name': None,\n",
    "                'elementarySchool_dist': None,\n",
    "                'elementarySchool_duration': None,\n",
    "                'preschool_name': None,\n",
    "                'preschool_dist': None,\n",
    "                'commutes': {},\n",
    "                'diff_3m': data.get('aptDiffOfPeriod', {}).get('3m'),\n",
    "                'diff_6m': data.get('aptDiffOfPeriod', {}).get('6m'),\n",
    "                'diff_1y': data.get('aptDiffOfPeriod', {}).get('1y'),\n",
    "                'diff_3y': data.get('aptDiffOfPeriod', {}).get('3y'),\n",
    "                'lat': data.get('lat'),\n",
    "                'lng': data.get('lng')\n",
    "            }\n",
    "            \n",
    "            for area in data.get('area', []):\n",
    "                area_info = {\n",
    "                    'no': area.get('no'),\n",
    "                    'private_area': area.get('private_area'),\n",
    "                    'public_area': area.get('public_area'),\n",
    "                    'real_trade_price': area.get('real_trade_price'),\n",
    "                    'real_rent_price': area.get('real_rent_price'),\n",
    "                    'real_rent_ratio': area.get('real_rent_ratio'),\n",
    "                    'max_real_trade_price': area.get('max_real_trade_price'),\n",
    "                    'max_real_rent_price': area.get('max_real_rent_price'),\n",
    "                    'total_household': area.get('total_household'),\n",
    "                    'type_official_price_data': area.get('type_official_price_data')\n",
    "                }\n",
    "                result['areas'].append(area_info)\n",
    "            \n",
    "            for subwayname in subwaynames:\n",
    "                result[subwayname] = ''\n",
    "\n",
    "            subway_info = {}\n",
    "            for subway in data.get('convenience', {}).get('subway', []):\n",
    "                line = subway.get('description', '')\n",
    "                station_dist = subway.get('dist', '')\n",
    "                \n",
    "                if line not in subway_info or station_dist < subway_info[line]:\n",
    "                    subway_info[line] = station_dist\n",
    "\n",
    "            for subwayname in subwaynames:\n",
    "                result[subwayname] = subway_info.get(subwayname, '')\n",
    "\n",
    "            for ktx in data.get('convenience', {}).get('ktx', []):\n",
    "                ktx_info = {\n",
    "                    'ktx_name': ktx.get('name'),\n",
    "                    'ktx_dist': ktx.get('dist')\n",
    "                }\n",
    "                result['ktxs'].append(ktx_info)\n",
    "            \n",
    "            for school in data.get('schoolInfo', {}).get('elementarySchool', {}).get('schools', []):\n",
    "                if school.get('isClosest'):\n",
    "                    result['elementarySchool_name'] = school.get('name')\n",
    "                    result['elementarySchool_dist'] = school.get('dist')\n",
    "                    result['elementarySchool_duration'] = school.get('duration')\n",
    "                    break\n",
    "            \n",
    "            for preschool in data.get('preschool', {}).get('childcares', []):\n",
    "                if preschool.get('isClosest'):\n",
    "                    result['preschool_name'] = preschool.get('name')\n",
    "                    result['preschool_dist'] = preschool.get('dist')\n",
    "                    break\n",
    "            \n",
    "            commute_destinations = ['강남', '을지로', '여의도', '판교', '구로', '잠실', '홍대', '명동']\n",
    "            for destination in commute_destinations:\n",
    "                result[destination] = None\n",
    "\n",
    "            for commute in data.get('commutes', []):\n",
    "                destination = commute.get('name')\n",
    "                time = commute.get('time')\n",
    "                if destination in commute_destinations:\n",
    "                    result[destination] = time\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "        if save :\n",
    "            df = pd.DataFrame(results)\n",
    "            df.to_csv(self.info_path, encoding='cp949', errors='replace', index=False)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def fetch_apt_info(self, apt_ids, apt_names, headless=True):\n",
    "        \"\"\"핵심기능2) 아파트 상세정보를 조회한다.\"\"\"\n",
    "        chrome_options = Options()\n",
    "        if headless : chrome_options.add_argument(\"--headless\")\n",
    "        # prefs = {\"profile.managed_default_content_settings.images\": 2}\n",
    "        # chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "        chrome_options.add_argument(\"--disable-gpu\")  # Disable GPU acceleration\n",
    "\n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "        tik = time.time()\n",
    "        idx = 0\n",
    "        for apt_id, apt_name in zip(apt_ids, apt_names) :\n",
    "            clear_output()\n",
    "            print(f'{idx}/{len(apt_ids)}')    \n",
    "            idx += 1\n",
    "            try:\n",
    "                driver.get(f\"https://hogangnono.com/apt/{apt_id}/0\")\n",
    "                tok = time.time()\n",
    "                print(f'들어오는데 {tok - tik}초가 걸림')\n",
    "                tik = time.time()\n",
    "                target_request = None\n",
    "                while not target_request:\n",
    "                    for request in driver.requests:\n",
    "                        if request.response and f\"apt/{apt_id}/detail\" in request.url:\n",
    "                            target_request = request\n",
    "                            break\n",
    "                    if not target_request:\n",
    "                        continue\n",
    "\n",
    "                if target_request:\n",
    "                    headers = {key: value for key, value in target_request.headers.items()}\n",
    "                    response = requests.get(target_request.url, headers=headers)\n",
    "                    response_json = response.json()\n",
    "                    with open(os.path.join(self.root_folder, f'{apt_id}_{apt_name}.json'), 'w', encoding='utf-8') as json_file:\n",
    "                        json.dump(response_json, json_file, ensure_ascii=False, indent=4)\n",
    "                    print(f\"Saved response for apt_id: {apt_id}\")\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"Target URL not found for apt_id: {apt_id}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process apt_id: {apt_id}, Error: {str(e)}\")\n",
    "\n",
    "        driver.quit()\n",
    "\n",
    "    def merge(self, type=\"merge_apts_info_real_trade\", real_trade='original') :\n",
    "        \"\"\"수집된 정보들을 통합합니다.\n",
    "        type : merge_apts_info_real_trade | merge_apts_info\"\"\"\n",
    "        print(\n",
    "            \"df len :\",len(self.info),\n",
    "            \"df_apts len :\",len(self.apts),\n",
    "            \"df_real_trade len :\",len(self.real_trade)\n",
    "        )\n",
    "        # 두 데이터프레임을 동일 id를 기준으로 합칩니다.\n",
    "        merged_df = pd.merge(self.apts, self.info, on='id')\n",
    "        if type== \"merge_apts_info\" :\n",
    "            merged_df.to_csv(self.merge_apts_info_path, encoding='cp949', index=False)\n",
    "        if type == \"merge_apts_info_real_trade\" :\n",
    "            if real_trade == 'original' :\n",
    "                merged_df = pd.merge(merged_df, self.real_trade, on='id')\n",
    "                merged_df.to_csv(self.merge_apts_info_real_trade_path, encoding='cp949', index=False)\n",
    "            elif real_trade == 'processed' :\n",
    "                merged_df = pd.merge(merged_df, self.filled_real_trade, on='id')\n",
    "                merged_df.to_csv(self.merge_apts_info_filled_real_trade_path, encoding='cp949', index=False)\n",
    "               \n",
    "        return merged_df\n",
    "        # # 합쳐진 데이터프레임을 반환합니다.\n",
    "        # len(merged_df)\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "# 사용 예시\n",
    "hgnn = Hogangnono()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgnn.fetch_apt_info(hgnn.apts['id'][:3], ['z','z','z',], headless = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgnn.merge(real_trade = 'processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = hgnn.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv(hgnn.filled_real_trade_path, encoding='cp949')\n",
    "a.loc[:,'2005-12':'2024-06'] = a.loc[:,'2005-12':'2024-06'].ffill(axis=1)\n",
    "a.loc[:,'2005-12':'2024-06'] = a.loc[:,'2005-12':'2024-06'].bfill(axis=1)\n",
    "a\n",
    "a.to_csv(hgnn.filled_real_trade_path, encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "def on_button_click():\n",
    "    messagebox.showinfo(\"Information\", \"Button clicked!\")\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Simple Tkinter App\")\n",
    "\n",
    "btn = tk.Button(root, text=\"Click Me\", command=on_button_click)\n",
    "btn.pack(pady=20)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgnn.real_tradehgnn.get_all_datas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgnn.real_trade[hgnn.date_list] = hgnn.real_trade[hgnn.date_list].interpolate(axis=1, limit_area='inside')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
